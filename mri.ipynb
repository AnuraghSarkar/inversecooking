{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import os.path\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import operator\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pylab as pl\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   \n",
    "from IPython.display import Image, display\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs: ', len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predictions Dataframe Initialisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_images(paths):\n",
    "    '''\n",
    "    Opens a batch of images, given the image path(s) as a list\n",
    "    '''\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        image = load_img(path, target_size=(224,224))\n",
    "        image = np.array(image)/255.0\n",
    "        images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "def get_labels(paths):\n",
    "    '''\n",
    "    it is possible to get the label from the path, just split the path by \"/\" and index -2\n",
    "    For example, /kaggle/input/brain-tumor-mri-dataset/Training/pituitary/Tr-pi_1020.jpg\n",
    "    splitting by \"/\" gives ['kaggle','input','brain-tumor-mri-dataset','Training','pituitary','Tr-pi_1020.jpg']\n",
    "    Now indexing -2 gives \"pituitary\"\n",
    "    '''\n",
    "    label = []\n",
    "    for path in paths:\n",
    "        path = path.split('/')[-2]\n",
    "        label.append(labels.index(path))\n",
    "    return label\n",
    "\n",
    "train_dir = r'Training/'\n",
    "test_dir = r'Testing/'\n",
    "\n",
    "train_paths = []\n",
    "test_paths = []\n",
    "\n",
    "\n",
    "for label in os.listdir(train_dir):\n",
    "    for file in os.listdir(train_dir+label):\n",
    "        train_paths.append(train_dir+label+'/'+file)\n",
    "\n",
    "\n",
    "for label in os.listdir(test_dir):\n",
    "    for file in os.listdir(test_dir+label):\n",
    "        test_paths.append(test_dir+label+'/'+file)\n",
    "\n",
    "labels_test = os.listdir(test_dir)\n",
    "labels_train = os.listdir(train_dir)\n",
    "\n",
    "model_predictions_train = pd.DataFrame(columns = ['3c2f','vgg16','vgg16_ctrained','resnet','resnet_ctrained','inception','inception_ctrained','actual'], \n",
    "                                       index = train_paths ).fillna('here')\n",
    "\n",
    "model_predictions_test = pd.DataFrame(columns = ['3c2f','vgg16','vgg16_ctrained','resnet','resnet_ctrained','inception','inception_ctrained','actual'], \n",
    "                                       index = test_paths ).fillna('here')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Augmenting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5712 images belonging to 4 classes.\n",
      "Found 1311 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "generator_train = ImageDataGenerator(rescale=1/255,\n",
    "                                     rotation_range=7,\n",
    "                                     horizontal_flip=True,\n",
    "                                     shear_range=0.1,\n",
    "                                     height_shift_range=0.07,\n",
    "                                     zoom_range=0.1)\n",
    "\n",
    "\n",
    "train = generator_train.flow_from_directory(r'Training', target_size=(224,224), # height and width of images to feed into CNN\n",
    "                                              batch_size=16, class_mode= \"categorical\", color_mode='rgb')\n",
    "\n",
    "\n",
    "generator_test = ImageDataGenerator(rescale=1/255,\n",
    "                                     rotation_range=7,\n",
    "                                     horizontal_flip=True,\n",
    "                                     shear_range=0.1,\n",
    "                                     height_shift_range=0.07,\n",
    "                                     zoom_range=0.1)\n",
    "\n",
    "\n",
    "test = generator_test.flow_from_directory(r'Testing', target_size=(224,224),\n",
    "                                              batch_size=16, class_mode= \"categorical\", color_mode='rgb')\n",
    "\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = r'Training'\n",
    "valid_path = r'Testing'\n",
    "\n",
    "folders = glob(r'Training/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predictions Dataframe Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "# Convolutional layer 1\n",
    "model1.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape=(224, 224, 3), activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides = 2))\n",
    "\n",
    "# Convolutional layer 2\n",
    "model1.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolutional layer 3\n",
    "model1.add(Conv2D(128,(3,3), activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "# Feedforward\n",
    "model1.add(Dense(units= 512, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(units=512, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.0001, clipvalue=0.5)\n",
    "model1.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                   metrics= ['categorical_accuracy'])\n",
    "\n",
    "model1_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model1_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "model1_mcp = ModelCheckpoint(filepath = r'temp\\model1_weights.h5', monitor = 'categorical_accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n",
    "history1 = model1.fit(train, steps_per_epoch=5712//16, epochs=120, validation_data=test, validation_steps= 1311//16, callbacks=[model1_es, model1_rlr, model1_mcp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('models/self_3conv_2ff.h5') is False:\n",
    "    model1.save('models/self_3conv_2ff.h5')\n",
    "    \n",
    "self_3conv_2ff = load_model('models/self_3conv_2ff.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - VGG16 (No Convolution Trained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 3s 0us/step\n",
      "Epoch 1/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.5659 - categorical_accuracy: 0.7303\n",
      "Epoch 1: categorical_accuracy improved from -inf to 0.73034, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 64s 352ms/step - loss: 1.5659 - categorical_accuracy: 0.7303 - val_loss: 0.5245 - val_categorical_accuracy: 0.8047 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3875 - categorical_accuracy: 0.8536\n",
      "Epoch 2: categorical_accuracy improved from 0.73034 to 0.85358, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 69s 389ms/step - loss: 0.3875 - categorical_accuracy: 0.8536 - val_loss: 0.6314 - val_categorical_accuracy: 0.7531 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3343 - categorical_accuracy: 0.8764\n",
      "Epoch 3: categorical_accuracy improved from 0.85358 to 0.87640, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 66s 372ms/step - loss: 0.3343 - categorical_accuracy: 0.8764 - val_loss: 0.3859 - val_categorical_accuracy: 0.8578 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3476 - categorical_accuracy: 0.8732\n",
      "Epoch 4: categorical_accuracy did not improve from 0.87640\n",
      "178/178 [==============================] - 55s 309ms/step - loss: 0.3476 - categorical_accuracy: 0.8732 - val_loss: 0.4774 - val_categorical_accuracy: 0.8469 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2863 - categorical_accuracy: 0.8947\n",
      "Epoch 5: categorical_accuracy improved from 0.87640 to 0.89466, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 72s 404ms/step - loss: 0.2863 - categorical_accuracy: 0.8947 - val_loss: 0.4200 - val_categorical_accuracy: 0.8562 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2709 - categorical_accuracy: 0.9031\n",
      "Epoch 6: categorical_accuracy improved from 0.89466 to 0.90309, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 70s 394ms/step - loss: 0.2709 - categorical_accuracy: 0.9031 - val_loss: 0.3345 - val_categorical_accuracy: 0.8703 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2164 - categorical_accuracy: 0.9263\n",
      "Epoch 7: categorical_accuracy improved from 0.90309 to 0.92626, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 67s 373ms/step - loss: 0.2164 - categorical_accuracy: 0.9263 - val_loss: 0.2899 - val_categorical_accuracy: 0.8813 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2152 - categorical_accuracy: 0.9235\n",
      "Epoch 8: categorical_accuracy did not improve from 0.92626\n",
      "178/178 [==============================] - 55s 310ms/step - loss: 0.2152 - categorical_accuracy: 0.9235 - val_loss: 0.2546 - val_categorical_accuracy: 0.8969 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2061 - categorical_accuracy: 0.9235\n",
      "Epoch 9: categorical_accuracy did not improve from 0.92626\n",
      "178/178 [==============================] - 55s 310ms/step - loss: 0.2061 - categorical_accuracy: 0.9235 - val_loss: 0.3279 - val_categorical_accuracy: 0.8562 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1862 - categorical_accuracy: 0.9329\n",
      "Epoch 10: categorical_accuracy improved from 0.92626 to 0.93294, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 68s 379ms/step - loss: 0.1862 - categorical_accuracy: 0.9329 - val_loss: 0.2349 - val_categorical_accuracy: 0.9016 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1569 - categorical_accuracy: 0.9421\n",
      "Epoch 11: categorical_accuracy improved from 0.93294 to 0.94206, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 66s 369ms/step - loss: 0.1569 - categorical_accuracy: 0.9421 - val_loss: 0.2950 - val_categorical_accuracy: 0.8797 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1573 - categorical_accuracy: 0.9393\n",
      "Epoch 12: categorical_accuracy did not improve from 0.94206\n",
      "178/178 [==============================] - 55s 309ms/step - loss: 0.1573 - categorical_accuracy: 0.9393 - val_loss: 0.2022 - val_categorical_accuracy: 0.9219 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1587 - categorical_accuracy: 0.9417\n",
      "Epoch 13: categorical_accuracy did not improve from 0.94206\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 0.1587 - categorical_accuracy: 0.9417 - val_loss: 0.2019 - val_categorical_accuracy: 0.9141 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1475 - categorical_accuracy: 0.9424\n",
      "Epoch 14: categorical_accuracy improved from 0.94206 to 0.94242, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 68s 384ms/step - loss: 0.1475 - categorical_accuracy: 0.9424 - val_loss: 0.2025 - val_categorical_accuracy: 0.9109 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1432 - categorical_accuracy: 0.9449\n",
      "Epoch 15: categorical_accuracy improved from 0.94242 to 0.94487, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 64s 361ms/step - loss: 0.1432 - categorical_accuracy: 0.9449 - val_loss: 0.1662 - val_categorical_accuracy: 0.9312 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1218 - categorical_accuracy: 0.9582\n",
      "Epoch 16: categorical_accuracy improved from 0.94487 to 0.95822, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 66s 370ms/step - loss: 0.1218 - categorical_accuracy: 0.9582 - val_loss: 0.4102 - val_categorical_accuracy: 0.8687 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1101 - categorical_accuracy: 0.9561\n",
      "Epoch 17: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 56s 310ms/step - loss: 0.1101 - categorical_accuracy: 0.9561 - val_loss: 0.1859 - val_categorical_accuracy: 0.9375 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1595 - categorical_accuracy: 0.9389\n",
      "Epoch 18: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 73s 407ms/step - loss: 0.1595 - categorical_accuracy: 0.9389 - val_loss: 0.3759 - val_categorical_accuracy: 0.8703 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1191 - categorical_accuracy: 0.9551\n",
      "Epoch 19: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 64s 357ms/step - loss: 0.1191 - categorical_accuracy: 0.9551 - val_loss: 0.2473 - val_categorical_accuracy: 0.9094 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0932 - categorical_accuracy: 0.9680\n",
      "Epoch 20: categorical_accuracy improved from 0.95822 to 0.96805, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 71s 401ms/step - loss: 0.0932 - categorical_accuracy: 0.9680 - val_loss: 0.2446 - val_categorical_accuracy: 0.9234 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0983 - categorical_accuracy: 0.9635\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 21: categorical_accuracy did not improve from 0.96805\n",
      "178/178 [==============================] - 59s 332ms/step - loss: 0.0983 - categorical_accuracy: 0.9635 - val_loss: 0.1937 - val_categorical_accuracy: 0.9375 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0569 - categorical_accuracy: 0.9803\n",
      "Epoch 22: categorical_accuracy improved from 0.96805 to 0.98034, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 70s 391ms/step - loss: 0.0569 - categorical_accuracy: 0.9803 - val_loss: 0.1431 - val_categorical_accuracy: 0.9406 - lr: 2.0000e-04\n",
      "Epoch 23/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0531 - categorical_accuracy: 0.9817\n",
      "Epoch 23: categorical_accuracy improved from 0.98034 to 0.98174, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 67s 376ms/step - loss: 0.0531 - categorical_accuracy: 0.9817 - val_loss: 0.1039 - val_categorical_accuracy: 0.9547 - lr: 2.0000e-04\n",
      "Epoch 24/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0457 - categorical_accuracy: 0.9842\n",
      "Epoch 24: categorical_accuracy improved from 0.98174 to 0.98420, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 66s 372ms/step - loss: 0.0457 - categorical_accuracy: 0.9842 - val_loss: 0.0714 - val_categorical_accuracy: 0.9797 - lr: 2.0000e-04\n",
      "Epoch 25/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0429 - categorical_accuracy: 0.9846\n",
      "Epoch 25: categorical_accuracy improved from 0.98420 to 0.98455, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 67s 375ms/step - loss: 0.0429 - categorical_accuracy: 0.9846 - val_loss: 0.1231 - val_categorical_accuracy: 0.9594 - lr: 2.0000e-04\n",
      "Epoch 26/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0422 - categorical_accuracy: 0.9867\n",
      "Epoch 26: categorical_accuracy improved from 0.98455 to 0.98666, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 68s 379ms/step - loss: 0.0422 - categorical_accuracy: 0.9867 - val_loss: 0.0895 - val_categorical_accuracy: 0.9672 - lr: 2.0000e-04\n",
      "Epoch 27/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0408 - categorical_accuracy: 0.9870\n",
      "Epoch 27: categorical_accuracy improved from 0.98666 to 0.98701, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 71s 396ms/step - loss: 0.0408 - categorical_accuracy: 0.9870 - val_loss: 0.1515 - val_categorical_accuracy: 0.9516 - lr: 2.0000e-04\n",
      "Epoch 28/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0391 - categorical_accuracy: 0.9870\n",
      "Epoch 28: categorical_accuracy did not improve from 0.98701\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 0.0391 - categorical_accuracy: 0.9870 - val_loss: 0.0855 - val_categorical_accuracy: 0.9703 - lr: 2.0000e-04\n",
      "Epoch 29/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0402 - categorical_accuracy: 0.9881\n",
      "Epoch 29: categorical_accuracy improved from 0.98701 to 0.98806, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 68s 383ms/step - loss: 0.0402 - categorical_accuracy: 0.9881 - val_loss: 0.0941 - val_categorical_accuracy: 0.9703 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0384 - categorical_accuracy: 0.9874\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 30: categorical_accuracy did not improve from 0.98806\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 0.0384 - categorical_accuracy: 0.9874 - val_loss: 0.0815 - val_categorical_accuracy: 0.9734 - lr: 2.0000e-04\n",
      "Epoch 31/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0321 - categorical_accuracy: 0.9905\n",
      "Epoch 31: categorical_accuracy improved from 0.98806 to 0.99052, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 67s 377ms/step - loss: 0.0321 - categorical_accuracy: 0.9905 - val_loss: 0.1010 - val_categorical_accuracy: 0.9641 - lr: 4.0000e-05\n",
      "Epoch 32/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0312 - categorical_accuracy: 0.9905\n",
      "Epoch 32: categorical_accuracy did not improve from 0.99052\n",
      "178/178 [==============================] - 56s 314ms/step - loss: 0.0312 - categorical_accuracy: 0.9905 - val_loss: 0.0986 - val_categorical_accuracy: 0.9641 - lr: 4.0000e-05\n",
      "Epoch 33/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0295 - categorical_accuracy: 0.9902\n",
      "Epoch 33: categorical_accuracy did not improve from 0.99052\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 0.0295 - categorical_accuracy: 0.9902 - val_loss: 0.1040 - val_categorical_accuracy: 0.9672 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0226 - categorical_accuracy: 0.9926\n",
      "Epoch 34: categorical_accuracy improved from 0.99052 to 0.99263, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 71s 397ms/step - loss: 0.0226 - categorical_accuracy: 0.9926 - val_loss: 0.1155 - val_categorical_accuracy: 0.9672 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0269 - categorical_accuracy: 0.9905\n",
      "Epoch 35: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 56s 311ms/step - loss: 0.0269 - categorical_accuracy: 0.9905 - val_loss: 0.1237 - val_categorical_accuracy: 0.9625 - lr: 4.0000e-05\n",
      "Epoch 36/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0304 - categorical_accuracy: 0.9895\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 36: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 56s 316ms/step - loss: 0.0304 - categorical_accuracy: 0.9895 - val_loss: 0.0996 - val_categorical_accuracy: 0.9672 - lr: 4.0000e-05\n",
      "Epoch 37/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0228 - categorical_accuracy: 0.9923\n",
      "Epoch 37: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 57s 320ms/step - loss: 0.0228 - categorical_accuracy: 0.9923 - val_loss: 0.1200 - val_categorical_accuracy: 0.9641 - lr: 8.0000e-06\n",
      "Epoch 38/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0258 - categorical_accuracy: 0.9919\n",
      "Epoch 38: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 57s 320ms/step - loss: 0.0258 - categorical_accuracy: 0.9919 - val_loss: 0.0853 - val_categorical_accuracy: 0.9672 - lr: 8.0000e-06\n",
      "Epoch 39/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0288 - categorical_accuracy: 0.9874\n",
      "Epoch 39: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 57s 320ms/step - loss: 0.0288 - categorical_accuracy: 0.9874 - val_loss: 0.0824 - val_categorical_accuracy: 0.9734 - lr: 8.0000e-06\n",
      "Epoch 40/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0243 - categorical_accuracy: 0.9923\n",
      "Epoch 40: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 58s 325ms/step - loss: 0.0243 - categorical_accuracy: 0.9923 - val_loss: 0.0599 - val_categorical_accuracy: 0.9766 - lr: 8.0000e-06\n",
      "Epoch 41/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0242 - categorical_accuracy: 0.9919\n",
      "Epoch 41: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 57s 322ms/step - loss: 0.0242 - categorical_accuracy: 0.9919 - val_loss: 0.0929 - val_categorical_accuracy: 0.9781 - lr: 8.0000e-06\n",
      "Epoch 42/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0227 - categorical_accuracy: 0.9933\n",
      "Epoch 42: categorical_accuracy improved from 0.99263 to 0.99333, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 68s 381ms/step - loss: 0.0227 - categorical_accuracy: 0.9933 - val_loss: 0.0797 - val_categorical_accuracy: 0.9734 - lr: 8.0000e-06\n",
      "Epoch 43/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0210 - categorical_accuracy: 0.9951\n",
      "Epoch 43: categorical_accuracy improved from 0.99333 to 0.99508, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 66s 372ms/step - loss: 0.0210 - categorical_accuracy: 0.9951 - val_loss: 0.0952 - val_categorical_accuracy: 0.9641 - lr: 8.0000e-06\n",
      "Epoch 44/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0200 - categorical_accuracy: 0.9916\n",
      "Epoch 44: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 56s 312ms/step - loss: 0.0200 - categorical_accuracy: 0.9916 - val_loss: 0.0664 - val_categorical_accuracy: 0.9781 - lr: 8.0000e-06\n",
      "Epoch 45/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0301 - categorical_accuracy: 0.9919\n",
      "Epoch 45: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 0.0301 - categorical_accuracy: 0.9919 - val_loss: 0.1226 - val_categorical_accuracy: 0.9625 - lr: 8.0000e-06\n",
      "Epoch 46/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0271 - categorical_accuracy: 0.9919\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 46: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 0.0271 - categorical_accuracy: 0.9919 - val_loss: 0.0960 - val_categorical_accuracy: 0.9719 - lr: 8.0000e-06\n",
      "Epoch 47/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0298 - categorical_accuracy: 0.9912\n",
      "Epoch 47: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 0.0298 - categorical_accuracy: 0.9912 - val_loss: 0.0729 - val_categorical_accuracy: 0.9766 - lr: 1.6000e-06\n",
      "Epoch 48/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0237 - categorical_accuracy: 0.9940\n",
      "Epoch 48: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 321ms/step - loss: 0.0237 - categorical_accuracy: 0.9940 - val_loss: 0.0644 - val_categorical_accuracy: 0.9812 - lr: 1.6000e-06\n",
      "Epoch 49/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0218 - categorical_accuracy: 0.9933\n",
      "Epoch 49: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 320ms/step - loss: 0.0218 - categorical_accuracy: 0.9933 - val_loss: 0.1038 - val_categorical_accuracy: 0.9656 - lr: 1.6000e-06\n",
      "Epoch 50/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0245 - categorical_accuracy: 0.9919\n",
      "Epoch 50: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 0.0245 - categorical_accuracy: 0.9919 - val_loss: 0.0961 - val_categorical_accuracy: 0.9688 - lr: 1.6000e-06\n",
      "Epoch 51/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0242 - categorical_accuracy: 0.9919\n",
      "Epoch 51: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 321ms/step - loss: 0.0242 - categorical_accuracy: 0.9919 - val_loss: 0.0861 - val_categorical_accuracy: 0.9734 - lr: 1.6000e-06\n",
      "Epoch 52/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0227 - categorical_accuracy: 0.9933\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 52: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 0.0227 - categorical_accuracy: 0.9933 - val_loss: 0.0669 - val_categorical_accuracy: 0.9797 - lr: 1.6000e-06\n",
      "Epoch 53/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0224 - categorical_accuracy: 0.9930\n",
      "Epoch 53: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 0.0224 - categorical_accuracy: 0.9930 - val_loss: 0.0971 - val_categorical_accuracy: 0.9719 - lr: 3.2000e-07\n",
      "Epoch 54/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0205 - categorical_accuracy: 0.9937\n",
      "Epoch 54: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 0.0205 - categorical_accuracy: 0.9937 - val_loss: 0.0912 - val_categorical_accuracy: 0.9719 - lr: 3.2000e-07\n",
      "Epoch 55/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0150 - categorical_accuracy: 0.9968\n",
      "Epoch 55: categorical_accuracy improved from 0.99508 to 0.99684, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 132s 741ms/step - loss: 0.0150 - categorical_accuracy: 0.9968 - val_loss: 0.0885 - val_categorical_accuracy: 0.9734 - lr: 3.2000e-07\n",
      "Epoch 56/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0222 - categorical_accuracy: 0.9909\n",
      "Epoch 56: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 152s 851ms/step - loss: 0.0222 - categorical_accuracy: 0.9909 - val_loss: 0.0935 - val_categorical_accuracy: 0.9766 - lr: 3.2000e-07\n",
      "Epoch 57/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0230 - categorical_accuracy: 0.9933\n",
      "Epoch 57: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 105s 588ms/step - loss: 0.0230 - categorical_accuracy: 0.9933 - val_loss: 0.0745 - val_categorical_accuracy: 0.9766 - lr: 3.2000e-07\n",
      "Epoch 58/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0227 - categorical_accuracy: 0.9923\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 58: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 54s 303ms/step - loss: 0.0227 - categorical_accuracy: 0.9923 - val_loss: 0.0986 - val_categorical_accuracy: 0.9672 - lr: 3.2000e-07\n",
      "Epoch 59/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0202 - categorical_accuracy: 0.9951\n",
      "Epoch 59: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 73s 410ms/step - loss: 0.0202 - categorical_accuracy: 0.9951 - val_loss: 0.0895 - val_categorical_accuracy: 0.9641 - lr: 6.4000e-08\n",
      "Epoch 60/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0210 - categorical_accuracy: 0.9937\n",
      "Epoch 60: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 66s 371ms/step - loss: 0.0210 - categorical_accuracy: 0.9937 - val_loss: 0.0870 - val_categorical_accuracy: 0.9703 - lr: 6.4000e-08\n",
      "Epoch 61/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0222 - categorical_accuracy: 0.9930\n",
      "Epoch 61: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 64s 360ms/step - loss: 0.0222 - categorical_accuracy: 0.9930 - val_loss: 0.0833 - val_categorical_accuracy: 0.9703 - lr: 6.4000e-08\n",
      "Epoch 62/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0218 - categorical_accuracy: 0.9916\n",
      "Epoch 62: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 55s 308ms/step - loss: 0.0218 - categorical_accuracy: 0.9916 - val_loss: 0.1021 - val_categorical_accuracy: 0.9703 - lr: 6.4000e-08\n",
      "Epoch 63/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0188 - categorical_accuracy: 0.9944\n",
      "Epoch 63: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 55s 306ms/step - loss: 0.0188 - categorical_accuracy: 0.9944 - val_loss: 0.0872 - val_categorical_accuracy: 0.9625 - lr: 6.4000e-08\n",
      "Epoch 64/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0263 - categorical_accuracy: 0.9912\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "\n",
      "Epoch 64: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 55s 310ms/step - loss: 0.0263 - categorical_accuracy: 0.9912 - val_loss: 0.0889 - val_categorical_accuracy: 0.9719 - lr: 6.4000e-08\n",
      "Epoch 65/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0230 - categorical_accuracy: 0.9916\n",
      "Epoch 65: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 55s 310ms/step - loss: 0.0230 - categorical_accuracy: 0.9916 - val_loss: 0.0836 - val_categorical_accuracy: 0.9734 - lr: 1.2800e-08\n",
      "Epoch 66/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0182 - categorical_accuracy: 0.9947\n",
      "Epoch 66: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 56s 312ms/step - loss: 0.0182 - categorical_accuracy: 0.9947 - val_loss: 0.0810 - val_categorical_accuracy: 0.9719 - lr: 1.2800e-08\n",
      "Epoch 67/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0274 - categorical_accuracy: 0.9930\n",
      "Epoch 67: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 56s 313ms/step - loss: 0.0274 - categorical_accuracy: 0.9930 - val_loss: 0.0678 - val_categorical_accuracy: 0.9734 - lr: 1.2800e-08\n",
      "Epoch 67: early stopping\n"
     ]
    }
   ],
   "source": [
    "vgg16_conv = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg16_conv.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "vgg_feedforward = Flatten()(vgg16_conv.output)\n",
    "vgg_feedforward = Dense(4096,activation = 'relu')(vgg_feedforward)\n",
    "vgg_feedforward = Dense(1024,activation = 'relu')(vgg_feedforward)\n",
    "\n",
    "prediction = Dense(4, activation='softmax')(vgg_feedforward)\n",
    "\n",
    "model_vgg16 = Model(inputs=vgg16_conv.input, outputs=prediction)\n",
    "\n",
    "model_vgg16.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model1_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model1_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "\n",
    "# Automatically saves the best weights of the model, based on best val_accuracy\n",
    "model1_mcp = ModelCheckpoint(filepath = r'temp\\model1_weights.h5', monitor = 'categorical_accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n",
    "vgg16_fit = model_vgg16.fit(\n",
    "  train,\n",
    "  validation_data=test,\n",
    "  epochs=100,\n",
    "  steps_per_epoch=5712//32,\n",
    "  validation_steps=1311//32,\n",
    "  callbacks=[model1_es, model1_rlr, model1_mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 222, 222, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 109, 109, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 52, 52, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,661,700\n",
      "Trainable params: 44,661,252\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('models/vgg16_4096_1024.h5') is False:\n",
    "    model1.save('models/vgg16_4096_1024.h5')\n",
    "\n",
    "vgg16_4096_1024 = load_model('models/vgg16_4096_1024.h5')\n",
    "print(vgg16_4096_1024.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 - VGG16 (Last Convolution Trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.4071 - categorical_accuracy: 0.2637\n",
      "Epoch 1: categorical_accuracy improved from -inf to 0.26369, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 62s 339ms/step - loss: 1.4071 - categorical_accuracy: 0.2637 - val_loss: 1.3822 - val_categorical_accuracy: 0.3281 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3850 - categorical_accuracy: 0.2707\n",
      "Epoch 2: categorical_accuracy improved from 0.26369 to 0.27072, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 61s 340ms/step - loss: 1.3850 - categorical_accuracy: 0.2707 - val_loss: 1.3825 - val_categorical_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3831 - categorical_accuracy: 0.2820\n",
      "Epoch 3: categorical_accuracy improved from 0.27072 to 0.28195, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 60s 339ms/step - loss: 1.3831 - categorical_accuracy: 0.2820 - val_loss: 1.3858 - val_categorical_accuracy: 0.2937 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3847 - categorical_accuracy: 0.2742\n",
      "Epoch 4: categorical_accuracy did not improve from 0.28195\n",
      "178/178 [==============================] - 58s 325ms/step - loss: 1.3847 - categorical_accuracy: 0.2742 - val_loss: 1.3817 - val_categorical_accuracy: 0.3172 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3837 - categorical_accuracy: 0.2834\n",
      "Epoch 5: categorical_accuracy improved from 0.28195 to 0.28336, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 322ms/step - loss: 1.3837 - categorical_accuracy: 0.2834 - val_loss: 1.3801 - val_categorical_accuracy: 0.3063 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3838 - categorical_accuracy: 0.2770\n",
      "Epoch 6: categorical_accuracy did not improve from 0.28336\n",
      "178/178 [==============================] - 57s 321ms/step - loss: 1.3838 - categorical_accuracy: 0.2770 - val_loss: 1.3808 - val_categorical_accuracy: 0.3016 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3825 - categorical_accuracy: 0.2834\n",
      "Epoch 7: categorical_accuracy did not improve from 0.28336\n",
      "178/178 [==============================] - 60s 334ms/step - loss: 1.3825 - categorical_accuracy: 0.2834 - val_loss: 1.3857 - val_categorical_accuracy: 0.2828 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3844 - categorical_accuracy: 0.2725\n",
      "Epoch 8: categorical_accuracy did not improve from 0.28336\n",
      "178/178 [==============================] - 62s 346ms/step - loss: 1.3844 - categorical_accuracy: 0.2725 - val_loss: 1.3822 - val_categorical_accuracy: 0.2953 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3825 - categorical_accuracy: 0.2890\n",
      "Epoch 9: categorical_accuracy improved from 0.28336 to 0.28897, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 61s 345ms/step - loss: 1.3825 - categorical_accuracy: 0.2890 - val_loss: 1.3802 - val_categorical_accuracy: 0.3172 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3833 - categorical_accuracy: 0.2827\n",
      "Epoch 10: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 62s 347ms/step - loss: 1.3833 - categorical_accuracy: 0.2827 - val_loss: 1.3772 - val_categorical_accuracy: 0.3328 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3841 - categorical_accuracy: 0.2753\n",
      "Epoch 11: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 63s 354ms/step - loss: 1.3841 - categorical_accuracy: 0.2753 - val_loss: 1.3837 - val_categorical_accuracy: 0.2906 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3822 - categorical_accuracy: 0.2837\n",
      "Epoch 12: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 61s 344ms/step - loss: 1.3822 - categorical_accuracy: 0.2837 - val_loss: 1.3799 - val_categorical_accuracy: 0.3047 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3831 - categorical_accuracy: 0.2823\n",
      "Epoch 13: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 61s 344ms/step - loss: 1.3831 - categorical_accuracy: 0.2823 - val_loss: 1.3839 - val_categorical_accuracy: 0.3063 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3833 - categorical_accuracy: 0.2795\n",
      "Epoch 14: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 68s 381ms/step - loss: 1.3833 - categorical_accuracy: 0.2795 - val_loss: 1.3810 - val_categorical_accuracy: 0.3094 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3834 - categorical_accuracy: 0.2753\n",
      "Epoch 15: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 61s 341ms/step - loss: 1.3834 - categorical_accuracy: 0.2753 - val_loss: 1.3768 - val_categorical_accuracy: 0.3359 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3834 - categorical_accuracy: 0.2798\n",
      "Epoch 16: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 64s 357ms/step - loss: 1.3834 - categorical_accuracy: 0.2798 - val_loss: 1.3820 - val_categorical_accuracy: 0.2984 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3827 - categorical_accuracy: 0.2837\n",
      "Epoch 17: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 66s 368ms/step - loss: 1.3827 - categorical_accuracy: 0.2837 - val_loss: 1.3810 - val_categorical_accuracy: 0.2922 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3830 - categorical_accuracy: 0.2812\n",
      "Epoch 18: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 64s 357ms/step - loss: 1.3830 - categorical_accuracy: 0.2812 - val_loss: 1.3796 - val_categorical_accuracy: 0.3234 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3830 - categorical_accuracy: 0.2851\n",
      "Epoch 19: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 61s 342ms/step - loss: 1.3830 - categorical_accuracy: 0.2851 - val_loss: 1.3805 - val_categorical_accuracy: 0.3172 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3821 - categorical_accuracy: 0.2802\n",
      "Epoch 20: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 65s 363ms/step - loss: 1.3821 - categorical_accuracy: 0.2802 - val_loss: 1.3756 - val_categorical_accuracy: 0.3281 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3850 - categorical_accuracy: 0.2686\n",
      "Epoch 21: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 67s 378ms/step - loss: 1.3850 - categorical_accuracy: 0.2686 - val_loss: 1.3816 - val_categorical_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3827 - categorical_accuracy: 0.2837\n",
      "Epoch 22: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 64s 359ms/step - loss: 1.3827 - categorical_accuracy: 0.2837 - val_loss: 1.3838 - val_categorical_accuracy: 0.2828 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3812 - categorical_accuracy: 0.2918\n",
      "Epoch 23: categorical_accuracy improved from 0.28897 to 0.29178, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 64s 358ms/step - loss: 1.3812 - categorical_accuracy: 0.2918 - val_loss: 1.3816 - val_categorical_accuracy: 0.3016 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3850 - categorical_accuracy: 0.2746\n",
      "Epoch 24: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 64s 359ms/step - loss: 1.3850 - categorical_accuracy: 0.2746 - val_loss: 1.3817 - val_categorical_accuracy: 0.3016 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3835 - categorical_accuracy: 0.2834\n",
      "Epoch 25: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 62s 349ms/step - loss: 1.3835 - categorical_accuracy: 0.2834 - val_loss: 1.3815 - val_categorical_accuracy: 0.3094 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3847 - categorical_accuracy: 0.2697\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 26: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 63s 351ms/step - loss: 1.3847 - categorical_accuracy: 0.2697 - val_loss: 1.3783 - val_categorical_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3835 - categorical_accuracy: 0.2791\n",
      "Epoch 27: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 62s 347ms/step - loss: 1.3835 - categorical_accuracy: 0.2791 - val_loss: 1.3807 - val_categorical_accuracy: 0.3063 - lr: 2.0000e-04\n",
      "Epoch 28/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3839 - categorical_accuracy: 0.2753\n",
      "Epoch 28: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 59s 332ms/step - loss: 1.3839 - categorical_accuracy: 0.2753 - val_loss: 1.3783 - val_categorical_accuracy: 0.3219 - lr: 2.0000e-04\n",
      "Epoch 29/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3828 - categorical_accuracy: 0.2791\n",
      "Epoch 29: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 59s 330ms/step - loss: 1.3828 - categorical_accuracy: 0.2791 - val_loss: 1.3820 - val_categorical_accuracy: 0.3125 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3832 - categorical_accuracy: 0.2791\n",
      "Epoch 30: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 59s 332ms/step - loss: 1.3832 - categorical_accuracy: 0.2791 - val_loss: 1.3823 - val_categorical_accuracy: 0.2984 - lr: 2.0000e-04\n",
      "Epoch 31/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3827 - categorical_accuracy: 0.2781\n",
      "Epoch 31: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 59s 329ms/step - loss: 1.3827 - categorical_accuracy: 0.2781 - val_loss: 1.3846 - val_categorical_accuracy: 0.2828 - lr: 2.0000e-04\n",
      "Epoch 32/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3837 - categorical_accuracy: 0.2830\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 32: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 60s 335ms/step - loss: 1.3837 - categorical_accuracy: 0.2830 - val_loss: 1.3844 - val_categorical_accuracy: 0.2906 - lr: 2.0000e-04\n",
      "Epoch 33/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3846 - categorical_accuracy: 0.2774\n",
      "Epoch 33: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 60s 335ms/step - loss: 1.3846 - categorical_accuracy: 0.2774 - val_loss: 1.3869 - val_categorical_accuracy: 0.2641 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3850 - categorical_accuracy: 0.2662\n",
      "Epoch 34: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 59s 332ms/step - loss: 1.3850 - categorical_accuracy: 0.2662 - val_loss: 1.3809 - val_categorical_accuracy: 0.3141 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3835 - categorical_accuracy: 0.2781\n",
      "Epoch 35: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 59s 330ms/step - loss: 1.3835 - categorical_accuracy: 0.2781 - val_loss: 1.3806 - val_categorical_accuracy: 0.3094 - lr: 4.0000e-05\n",
      "Epoch 35: early stopping\n"
     ]
    }
   ],
   "source": [
    "vgg16_conv = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg16_conv.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "vgg_feedforward = Flatten()(vgg16_conv.output)\n",
    "vgg_feedforward = Dense(64,activation = 'relu')(vgg_feedforward)\n",
    "vgg_feedforward = Dense(16,activation = 'relu')(vgg_feedforward)\n",
    "\n",
    "prediction = Dense(len(folders), activation='softmax')(vgg_feedforward)\n",
    "\n",
    "model_vgg16 = Model(inputs=vgg16_conv.input, outputs=prediction)\n",
    "\n",
    "model_vgg16.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model1_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model1_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "\n",
    "# Automatically saves the best weights of the model, based on best val_accuracy\n",
    "model1_mcp = ModelCheckpoint(filepath = r'temp\\model1_weights.h5', monitor = 'categorical_accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n",
    "vgg16_fit = model_vgg16.fit(\n",
    "  train,\n",
    "  validation_data=test,\n",
    "  epochs=100,\n",
    "  steps_per_epoch=5712//32,\n",
    "  validation_steps=1311//32,\n",
    "  callbacks=[model1_es, model1_rlr, model1_mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                1605696   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,321,492\n",
      "Trainable params: 8,686,228\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('models/vgg16_64_16_last_conv_train.h5') is False:\n",
    "    model_vgg16.save('models/vgg16_64_16_last_conv_train.h5')\n",
    "\n",
    "vgg16_64_16_last_conv_trained = load_model('models/vgg16_64_16_last_conv_train.h5')\n",
    "print(vgg16_64_16_last_conv_trained.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 - ResNet150 (No Convolution Trained) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234545216/234545216 [==============================] - 24s 0us/step\n",
      "Epoch 1/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 3.8381 - categorical_accuracy: 0.7900\n",
      "Epoch 1: categorical_accuracy improved from -inf to 0.79003, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 107s 532ms/step - loss: 3.8381 - categorical_accuracy: 0.7900 - val_loss: 4.1131 - val_categorical_accuracy: 0.8141 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 3.0886 - categorical_accuracy: 0.8652\n",
      "Epoch 2: categorical_accuracy improved from 0.79003 to 0.86517, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 69s 386ms/step - loss: 3.0886 - categorical_accuracy: 0.8652 - val_loss: 3.2448 - val_categorical_accuracy: 0.8703 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 2.7640 - categorical_accuracy: 0.8908\n",
      "Epoch 3: categorical_accuracy improved from 0.86517 to 0.89080, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 61s 341ms/step - loss: 2.7640 - categorical_accuracy: 0.8908 - val_loss: 2.5606 - val_categorical_accuracy: 0.9031 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.9824 - categorical_accuracy: 0.9182\n",
      "Epoch 4: categorical_accuracy improved from 0.89080 to 0.91819, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 59s 326ms/step - loss: 1.9824 - categorical_accuracy: 0.9182 - val_loss: 2.5364 - val_categorical_accuracy: 0.9031 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 2.2321 - categorical_accuracy: 0.9185\n",
      "Epoch 5: categorical_accuracy improved from 0.91819 to 0.91854, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 321ms/step - loss: 2.2321 - categorical_accuracy: 0.9185 - val_loss: 2.6831 - val_categorical_accuracy: 0.9156 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.9184 - categorical_accuracy: 0.9287\n",
      "Epoch 6: categorical_accuracy improved from 0.91854 to 0.92872, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 1.9184 - categorical_accuracy: 0.9287 - val_loss: 2.1032 - val_categorical_accuracy: 0.9156 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.7831 - categorical_accuracy: 0.9294\n",
      "Epoch 7: categorical_accuracy improved from 0.92872 to 0.92942, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 320ms/step - loss: 1.7831 - categorical_accuracy: 0.9294 - val_loss: 3.0945 - val_categorical_accuracy: 0.9062 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.5755 - categorical_accuracy: 0.9424\n",
      "Epoch 8: categorical_accuracy improved from 0.92942 to 0.94242, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 56s 315ms/step - loss: 1.5755 - categorical_accuracy: 0.9424 - val_loss: 1.6030 - val_categorical_accuracy: 0.9359 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3740 - categorical_accuracy: 0.9505\n",
      "Epoch 9: categorical_accuracy improved from 0.94242 to 0.95049, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 1.3740 - categorical_accuracy: 0.9505 - val_loss: 1.9588 - val_categorical_accuracy: 0.9344 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.6037 - categorical_accuracy: 0.9417\n",
      "Epoch 10: categorical_accuracy did not improve from 0.95049\n",
      "178/178 [==============================] - 52s 291ms/step - loss: 1.6037 - categorical_accuracy: 0.9417 - val_loss: 2.3160 - val_categorical_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.2297 - categorical_accuracy: 0.9565\n",
      "Epoch 11: categorical_accuracy improved from 0.95049 to 0.95646, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 1.2297 - categorical_accuracy: 0.9565 - val_loss: 2.5801 - val_categorical_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3642 - categorical_accuracy: 0.9582\n",
      "Epoch 12: categorical_accuracy improved from 0.95646 to 0.95822, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 1.3642 - categorical_accuracy: 0.9582 - val_loss: 2.3457 - val_categorical_accuracy: 0.9203 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3377 - categorical_accuracy: 0.9508\n",
      "Epoch 13: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 52s 291ms/step - loss: 1.3377 - categorical_accuracy: 0.9508 - val_loss: 2.8326 - val_categorical_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.5956 - categorical_accuracy: 0.9526\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 14: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 54s 301ms/step - loss: 1.5956 - categorical_accuracy: 0.9526 - val_loss: 3.5592 - val_categorical_accuracy: 0.9141 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.8763 - categorical_accuracy: 0.9726\n",
      "Epoch 15: categorical_accuracy improved from 0.95822 to 0.97261, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 320ms/step - loss: 0.8763 - categorical_accuracy: 0.9726 - val_loss: 1.1883 - val_categorical_accuracy: 0.9594 - lr: 2.0000e-04\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4261 - categorical_accuracy: 0.9810\n",
      "Epoch 16: categorical_accuracy improved from 0.97261 to 0.98104, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 321ms/step - loss: 0.4261 - categorical_accuracy: 0.9810 - val_loss: 1.2461 - val_categorical_accuracy: 0.9547 - lr: 2.0000e-04\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.6029 - categorical_accuracy: 0.9782\n",
      "Epoch 17: categorical_accuracy did not improve from 0.98104\n",
      "178/178 [==============================] - 53s 294ms/step - loss: 0.6029 - categorical_accuracy: 0.9782 - val_loss: 0.5958 - val_categorical_accuracy: 0.9672 - lr: 2.0000e-04\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3923 - categorical_accuracy: 0.9796\n",
      "Epoch 18: categorical_accuracy did not improve from 0.98104\n",
      "178/178 [==============================] - 53s 295ms/step - loss: 0.3923 - categorical_accuracy: 0.9796 - val_loss: 1.0593 - val_categorical_accuracy: 0.9578 - lr: 2.0000e-04\n",
      "Epoch 19/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3100 - categorical_accuracy: 0.9828\n",
      "Epoch 19: categorical_accuracy improved from 0.98104 to 0.98279, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 326ms/step - loss: 0.3100 - categorical_accuracy: 0.9828 - val_loss: 1.1217 - val_categorical_accuracy: 0.9625 - lr: 2.0000e-04\n",
      "Epoch 20/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3785 - categorical_accuracy: 0.9824\n",
      "Epoch 20: categorical_accuracy did not improve from 0.98279\n",
      "178/178 [==============================] - 53s 295ms/step - loss: 0.3785 - categorical_accuracy: 0.9824 - val_loss: 1.3372 - val_categorical_accuracy: 0.9609 - lr: 2.0000e-04\n",
      "Epoch 21/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3281 - categorical_accuracy: 0.9814\n",
      "Epoch 21: categorical_accuracy did not improve from 0.98279\n",
      "178/178 [==============================] - 53s 297ms/step - loss: 0.3281 - categorical_accuracy: 0.9814 - val_loss: 0.8023 - val_categorical_accuracy: 0.9688 - lr: 2.0000e-04\n",
      "Epoch 22/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3610 - categorical_accuracy: 0.9860\n",
      "Epoch 22: categorical_accuracy improved from 0.98279 to 0.98596, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 325ms/step - loss: 0.3610 - categorical_accuracy: 0.9860 - val_loss: 0.9564 - val_categorical_accuracy: 0.9609 - lr: 2.0000e-04\n",
      "Epoch 23/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2801 - categorical_accuracy: 0.9853\n",
      "Epoch 23: categorical_accuracy did not improve from 0.98596\n",
      "178/178 [==============================] - 53s 296ms/step - loss: 0.2801 - categorical_accuracy: 0.9853 - val_loss: 0.5653 - val_categorical_accuracy: 0.9656 - lr: 2.0000e-04\n",
      "Epoch 24/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2507 - categorical_accuracy: 0.9874\n",
      "Epoch 24: categorical_accuracy improved from 0.98596 to 0.98736, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 323ms/step - loss: 0.2507 - categorical_accuracy: 0.9874 - val_loss: 1.2418 - val_categorical_accuracy: 0.9516 - lr: 2.0000e-04\n",
      "Epoch 25/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2140 - categorical_accuracy: 0.9863\n",
      "Epoch 25: categorical_accuracy did not improve from 0.98736\n",
      "178/178 [==============================] - 53s 297ms/step - loss: 0.2140 - categorical_accuracy: 0.9863 - val_loss: 1.0700 - val_categorical_accuracy: 0.9594 - lr: 2.0000e-04\n",
      "Epoch 26/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2682 - categorical_accuracy: 0.9870\n",
      "Epoch 26: categorical_accuracy did not improve from 0.98736\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.2682 - categorical_accuracy: 0.9870 - val_loss: 0.6802 - val_categorical_accuracy: 0.9703 - lr: 2.0000e-04\n",
      "Epoch 27/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4651 - categorical_accuracy: 0.9821\n",
      "Epoch 27: categorical_accuracy did not improve from 0.98736\n",
      "178/178 [==============================] - 53s 300ms/step - loss: 0.4651 - categorical_accuracy: 0.9821 - val_loss: 1.0255 - val_categorical_accuracy: 0.9688 - lr: 2.0000e-04\n",
      "Epoch 28/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3278 - categorical_accuracy: 0.9821\n",
      "Epoch 28: categorical_accuracy did not improve from 0.98736\n",
      "178/178 [==============================] - 54s 300ms/step - loss: 0.3278 - categorical_accuracy: 0.9821 - val_loss: 0.6105 - val_categorical_accuracy: 0.9766 - lr: 2.0000e-04\n",
      "Epoch 29/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2272 - categorical_accuracy: 0.9891\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 29: categorical_accuracy improved from 0.98736 to 0.98912, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 324ms/step - loss: 0.2272 - categorical_accuracy: 0.9891 - val_loss: 1.2003 - val_categorical_accuracy: 0.9594 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1896 - categorical_accuracy: 0.9877\n",
      "Epoch 30: categorical_accuracy did not improve from 0.98912\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1896 - categorical_accuracy: 0.9877 - val_loss: 1.0536 - val_categorical_accuracy: 0.9625 - lr: 4.0000e-05\n",
      "Epoch 31/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1498 - categorical_accuracy: 0.9916\n",
      "Epoch 31: categorical_accuracy improved from 0.98912 to 0.99157, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 63s 353ms/step - loss: 0.1498 - categorical_accuracy: 0.9916 - val_loss: 0.6922 - val_categorical_accuracy: 0.9703 - lr: 4.0000e-05\n",
      "Epoch 32/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1426 - categorical_accuracy: 0.9909\n",
      "Epoch 32: categorical_accuracy did not improve from 0.99157\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1426 - categorical_accuracy: 0.9909 - val_loss: 0.5339 - val_categorical_accuracy: 0.9750 - lr: 4.0000e-05\n",
      "Epoch 33/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1501 - categorical_accuracy: 0.9881\n",
      "Epoch 33: categorical_accuracy did not improve from 0.99157\n",
      "178/178 [==============================] - 53s 300ms/step - loss: 0.1501 - categorical_accuracy: 0.9881 - val_loss: 0.7968 - val_categorical_accuracy: 0.9719 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1456 - categorical_accuracy: 0.9937\n",
      "Epoch 34: categorical_accuracy improved from 0.99157 to 0.99368, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 326ms/step - loss: 0.1456 - categorical_accuracy: 0.9937 - val_loss: 1.0532 - val_categorical_accuracy: 0.9641 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1097 - categorical_accuracy: 0.9891\n",
      "Epoch 35: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1097 - categorical_accuracy: 0.9891 - val_loss: 0.6241 - val_categorical_accuracy: 0.9719 - lr: 4.0000e-05\n",
      "Epoch 36/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1214 - categorical_accuracy: 0.9902\n",
      "Epoch 36: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1214 - categorical_accuracy: 0.9902 - val_loss: 0.7752 - val_categorical_accuracy: 0.9688 - lr: 4.0000e-05\n",
      "Epoch 37/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0895 - categorical_accuracy: 0.9930\n",
      "Epoch 37: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 55s 310ms/step - loss: 0.0895 - categorical_accuracy: 0.9930 - val_loss: 0.8077 - val_categorical_accuracy: 0.9609 - lr: 4.0000e-05\n",
      "Epoch 38/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1845 - categorical_accuracy: 0.9916\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 38: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1845 - categorical_accuracy: 0.9916 - val_loss: 0.6946 - val_categorical_accuracy: 0.9703 - lr: 4.0000e-05\n",
      "Epoch 39/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1511 - categorical_accuracy: 0.9923\n",
      "Epoch 39: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1511 - categorical_accuracy: 0.9923 - val_loss: 0.8041 - val_categorical_accuracy: 0.9688 - lr: 8.0000e-06\n",
      "Epoch 40/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1825 - categorical_accuracy: 0.9884\n",
      "Epoch 40: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1825 - categorical_accuracy: 0.9884 - val_loss: 0.6474 - val_categorical_accuracy: 0.9719 - lr: 8.0000e-06\n",
      "Epoch 41/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1662 - categorical_accuracy: 0.9877\n",
      "Epoch 41: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1662 - categorical_accuracy: 0.9877 - val_loss: 0.8556 - val_categorical_accuracy: 0.9703 - lr: 8.0000e-06\n",
      "Epoch 42/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0934 - categorical_accuracy: 0.9937\n",
      "Epoch 42: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.0934 - categorical_accuracy: 0.9937 - val_loss: 1.0211 - val_categorical_accuracy: 0.9703 - lr: 8.0000e-06\n",
      "Epoch 43/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1363 - categorical_accuracy: 0.9916\n",
      "Epoch 43: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1363 - categorical_accuracy: 0.9916 - val_loss: 1.3061 - val_categorical_accuracy: 0.9641 - lr: 8.0000e-06\n",
      "Epoch 44/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0637 - categorical_accuracy: 0.9947\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 44: categorical_accuracy improved from 0.99368 to 0.99473, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 325ms/step - loss: 0.0637 - categorical_accuracy: 0.9947 - val_loss: 0.8738 - val_categorical_accuracy: 0.9719 - lr: 8.0000e-06\n",
      "Epoch 45/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1414 - categorical_accuracy: 0.9923\n",
      "Epoch 45: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 296ms/step - loss: 0.1414 - categorical_accuracy: 0.9923 - val_loss: 0.5309 - val_categorical_accuracy: 0.9719 - lr: 1.6000e-06\n",
      "Epoch 46/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1623 - categorical_accuracy: 0.9909\n",
      "Epoch 46: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1623 - categorical_accuracy: 0.9909 - val_loss: 0.9188 - val_categorical_accuracy: 0.9641 - lr: 1.6000e-06\n",
      "Epoch 47/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0800 - categorical_accuracy: 0.9947\n",
      "Epoch 47: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 54s 304ms/step - loss: 0.0800 - categorical_accuracy: 0.9947 - val_loss: 1.0642 - val_categorical_accuracy: 0.9641 - lr: 1.6000e-06\n",
      "Epoch 48/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0798 - categorical_accuracy: 0.9930\n",
      "Epoch 48: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 297ms/step - loss: 0.0798 - categorical_accuracy: 0.9930 - val_loss: 0.3697 - val_categorical_accuracy: 0.9828 - lr: 1.6000e-06\n",
      "Epoch 49/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1160 - categorical_accuracy: 0.9926\n",
      "Epoch 49: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1160 - categorical_accuracy: 0.9926 - val_loss: 0.8846 - val_categorical_accuracy: 0.9719 - lr: 1.6000e-06\n",
      "Epoch 50/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1704 - categorical_accuracy: 0.9905\n",
      "Epoch 50: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1704 - categorical_accuracy: 0.9905 - val_loss: 0.6654 - val_categorical_accuracy: 0.9766 - lr: 1.6000e-06\n",
      "Epoch 51/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0842 - categorical_accuracy: 0.9926\n",
      "Epoch 51: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 297ms/step - loss: 0.0842 - categorical_accuracy: 0.9926 - val_loss: 0.7456 - val_categorical_accuracy: 0.9734 - lr: 1.6000e-06\n",
      "Epoch 52/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1415 - categorical_accuracy: 0.9902\n",
      "Epoch 52: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 54s 303ms/step - loss: 0.1415 - categorical_accuracy: 0.9902 - val_loss: 0.5013 - val_categorical_accuracy: 0.9734 - lr: 1.6000e-06\n",
      "Epoch 53/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1166 - categorical_accuracy: 0.9916\n",
      "Epoch 53: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1166 - categorical_accuracy: 0.9916 - val_loss: 0.6591 - val_categorical_accuracy: 0.9781 - lr: 1.6000e-06\n",
      "Epoch 54/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0938 - categorical_accuracy: 0.9937\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 54: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.0938 - categorical_accuracy: 0.9937 - val_loss: 0.9038 - val_categorical_accuracy: 0.9688 - lr: 1.6000e-06\n",
      "Epoch 55/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1513 - categorical_accuracy: 0.9926\n",
      "Epoch 55: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 54s 301ms/step - loss: 0.1513 - categorical_accuracy: 0.9926 - val_loss: 0.6386 - val_categorical_accuracy: 0.9781 - lr: 3.2000e-07\n",
      "Epoch 56/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1064 - categorical_accuracy: 0.9937\n",
      "Epoch 56: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 52s 292ms/step - loss: 0.1064 - categorical_accuracy: 0.9937 - val_loss: 0.4267 - val_categorical_accuracy: 0.9719 - lr: 3.2000e-07\n",
      "Epoch 56: early stopping\n"
     ]
    }
   ],
   "source": [
    "ResNet_conv = ResNet152V2(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in ResNet_conv.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "resnet_feedforword = Flatten()(ResNet_conv.output)\n",
    "\n",
    "prediction = Dense(len(folders), activation='softmax')(resnet_feedforword)\n",
    "\n",
    "model_ResNet = Model(inputs= ResNet_conv.input, outputs=prediction)\n",
    "\n",
    "model_ResNet.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "model1_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model1_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "model1_mcp = ModelCheckpoint(filepath = r'temp\\model1_weights.h5', monitor = 'categorical_accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n",
    "model_ResNet_fit = model_ResNet.fit(\n",
    "  train,\n",
    "  validation_data=test,\n",
    "  epochs=100,\n",
    "  steps_per_epoch=5712//32,\n",
    "  validation_steps=1311//32,\n",
    "  callbacks=[model1_es, model1_rlr, model1_mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('models/resnet152.h5') is False:\n",
    "    model_ResNet.save('models/resnet152.h5')\n",
    "\n",
    "resnet152 = load_model('models/resnet152.h5')\n",
    "print(resnet152.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5 - ResNet150 (Last 2 Convolution Trained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 2.2147 - categorical_accuracy: 0.5358\n",
      "Epoch 1: categorical_accuracy improved from -inf to 0.53581, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 178s 886ms/step - loss: 2.2147 - categorical_accuracy: 0.5358 - val_loss: 16159.0596 - val_categorical_accuracy: 0.3031 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.9334 - categorical_accuracy: 0.6706\n",
      "Epoch 2: categorical_accuracy improved from 0.53581 to 0.67065, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 152s 855ms/step - loss: 0.9334 - categorical_accuracy: 0.6706 - val_loss: 113.4720 - val_categorical_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.1337 - categorical_accuracy: 0.7184\n",
      "Epoch 3: categorical_accuracy improved from 0.67065 to 0.71840, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 153s 857ms/step - loss: 1.1337 - categorical_accuracy: 0.7184 - val_loss: 1840594.6250 - val_categorical_accuracy: 0.3063 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.5705 - categorical_accuracy: 0.6594\n",
      "Epoch 4: categorical_accuracy did not improve from 0.71840\n",
      "178/178 [==============================] - 142s 795ms/step - loss: 1.5705 - categorical_accuracy: 0.6594 - val_loss: 1.0381 - val_categorical_accuracy: 0.6344 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.7102 - categorical_accuracy: 0.7338\n",
      "Epoch 5: categorical_accuracy improved from 0.71840 to 0.73385, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 158s 889ms/step - loss: 0.7102 - categorical_accuracy: 0.7338 - val_loss: 1.4427 - val_categorical_accuracy: 0.5938 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.6993 - categorical_accuracy: 0.7633\n",
      "Epoch 6: categorical_accuracy improved from 0.73385 to 0.76334, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 162s 909ms/step - loss: 0.6993 - categorical_accuracy: 0.7633 - val_loss: 1.2326 - val_categorical_accuracy: 0.5641 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.6875 - categorical_accuracy: 0.7690\n",
      "Epoch 7: categorical_accuracy improved from 0.76334 to 0.76896, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 155s 869ms/step - loss: 0.6875 - categorical_accuracy: 0.7690 - val_loss: 0.8471 - val_categorical_accuracy: 0.7078 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.5168 - categorical_accuracy: 0.8069\n",
      "Epoch 8: categorical_accuracy improved from 0.76896 to 0.80688, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 153s 861ms/step - loss: 0.5168 - categorical_accuracy: 0.8069 - val_loss: 0.8997 - val_categorical_accuracy: 0.7188 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.5128 - categorical_accuracy: 0.8157\n",
      "Epoch 9: categorical_accuracy improved from 0.80688 to 0.81566, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 154s 862ms/step - loss: 0.5128 - categorical_accuracy: 0.8157 - val_loss: 2.1558 - val_categorical_accuracy: 0.4578 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.7317 - categorical_accuracy: 0.7988\n",
      "Epoch 10: categorical_accuracy did not improve from 0.81566\n",
      "178/178 [==============================] - 138s 772ms/step - loss: 0.7317 - categorical_accuracy: 0.7988 - val_loss: 2.9104 - val_categorical_accuracy: 0.4141 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.5687 - categorical_accuracy: 0.8234\n",
      "Epoch 11: categorical_accuracy improved from 0.81566 to 0.82338, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 150s 841ms/step - loss: 0.5687 - categorical_accuracy: 0.8234 - val_loss: 2.9957 - val_categorical_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4354 - categorical_accuracy: 0.8413\n",
      "Epoch 12: categorical_accuracy improved from 0.82338 to 0.84129, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 150s 841ms/step - loss: 0.4354 - categorical_accuracy: 0.8413 - val_loss: 0.6697 - val_categorical_accuracy: 0.7734 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4072 - categorical_accuracy: 0.8483\n",
      "Epoch 13: categorical_accuracy improved from 0.84129 to 0.84831, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 149s 837ms/step - loss: 0.4072 - categorical_accuracy: 0.8483 - val_loss: 0.5353 - val_categorical_accuracy: 0.8094 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4090 - categorical_accuracy: 0.8497\n",
      "Epoch 14: categorical_accuracy improved from 0.84831 to 0.84972, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 149s 837ms/step - loss: 0.4090 - categorical_accuracy: 0.8497 - val_loss: 0.9414 - val_categorical_accuracy: 0.6187 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4035 - categorical_accuracy: 0.8504\n",
      "Epoch 15: categorical_accuracy improved from 0.84972 to 0.85042, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 150s 839ms/step - loss: 0.4035 - categorical_accuracy: 0.8504 - val_loss: 0.8832 - val_categorical_accuracy: 0.7125 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3922 - categorical_accuracy: 0.8578\n",
      "Epoch 16: categorical_accuracy improved from 0.85042 to 0.85779, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 145s 815ms/step - loss: 0.3922 - categorical_accuracy: 0.8578 - val_loss: 0.6595 - val_categorical_accuracy: 0.7156 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3550 - categorical_accuracy: 0.8715\n",
      "Epoch 17: categorical_accuracy improved from 0.85779 to 0.87149, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 145s 815ms/step - loss: 0.3550 - categorical_accuracy: 0.8715 - val_loss: 1.0640 - val_categorical_accuracy: 0.6484 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3549 - categorical_accuracy: 0.8750\n",
      "Epoch 18: categorical_accuracy improved from 0.87149 to 0.87500, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 146s 819ms/step - loss: 0.3549 - categorical_accuracy: 0.8750 - val_loss: 1.2233 - val_categorical_accuracy: 0.6484 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3629 - categorical_accuracy: 0.8718\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 19: categorical_accuracy did not improve from 0.87500\n",
      "178/178 [==============================] - 133s 744ms/step - loss: 0.3629 - categorical_accuracy: 0.8718 - val_loss: 0.6446 - val_categorical_accuracy: 0.8078 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2529 - categorical_accuracy: 0.9098\n",
      "Epoch 20: categorical_accuracy improved from 0.87500 to 0.90976, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 145s 816ms/step - loss: 0.2529 - categorical_accuracy: 0.9098 - val_loss: 0.3786 - val_categorical_accuracy: 0.8562 - lr: 2.0000e-04\n",
      "Epoch 21/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2604 - categorical_accuracy: 0.9006\n",
      "Epoch 21: categorical_accuracy did not improve from 0.90976\n",
      "178/178 [==============================] - 133s 746ms/step - loss: 0.2604 - categorical_accuracy: 0.9006 - val_loss: 0.4118 - val_categorical_accuracy: 0.8531 - lr: 2.0000e-04\n",
      "Epoch 22/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2465 - categorical_accuracy: 0.9140\n",
      "Epoch 22: categorical_accuracy improved from 0.90976 to 0.91397, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 167s 937ms/step - loss: 0.2465 - categorical_accuracy: 0.9140 - val_loss: 0.3409 - val_categorical_accuracy: 0.8703 - lr: 2.0000e-04\n",
      "Epoch 23/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2203 - categorical_accuracy: 0.9206\n",
      "Epoch 23: categorical_accuracy improved from 0.91397 to 0.92065, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 156s 874ms/step - loss: 0.2203 - categorical_accuracy: 0.9206 - val_loss: 0.2983 - val_categorical_accuracy: 0.8953 - lr: 2.0000e-04\n",
      "Epoch 24/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2083 - categorical_accuracy: 0.9217\n",
      "Epoch 24: categorical_accuracy improved from 0.92065 to 0.92170, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 152s 855ms/step - loss: 0.2083 - categorical_accuracy: 0.9217 - val_loss: 0.2622 - val_categorical_accuracy: 0.9016 - lr: 2.0000e-04\n",
      "Epoch 25/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2222 - categorical_accuracy: 0.9231\n",
      "Epoch 25: categorical_accuracy improved from 0.92170 to 0.92310, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 154s 863ms/step - loss: 0.2222 - categorical_accuracy: 0.9231 - val_loss: 0.5626 - val_categorical_accuracy: 0.7844 - lr: 2.0000e-04\n",
      "Epoch 26/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1996 - categorical_accuracy: 0.9298\n",
      "Epoch 26: categorical_accuracy improved from 0.92310 to 0.92978, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 155s 870ms/step - loss: 0.1996 - categorical_accuracy: 0.9298 - val_loss: 0.4263 - val_categorical_accuracy: 0.8547 - lr: 2.0000e-04\n",
      "Epoch 27/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1946 - categorical_accuracy: 0.9301\n",
      "Epoch 27: categorical_accuracy improved from 0.92978 to 0.93013, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 154s 864ms/step - loss: 0.1946 - categorical_accuracy: 0.9301 - val_loss: 0.2795 - val_categorical_accuracy: 0.8984 - lr: 2.0000e-04\n",
      "Epoch 28/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1889 - categorical_accuracy: 0.9238\n",
      "Epoch 28: categorical_accuracy did not improve from 0.93013\n",
      "178/178 [==============================] - 141s 793ms/step - loss: 0.1889 - categorical_accuracy: 0.9238 - val_loss: 0.3556 - val_categorical_accuracy: 0.8734 - lr: 2.0000e-04\n",
      "Epoch 29/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1907 - categorical_accuracy: 0.9329\n",
      "Epoch 29: categorical_accuracy improved from 0.93013 to 0.93294, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 156s 876ms/step - loss: 0.1907 - categorical_accuracy: 0.9329 - val_loss: 0.2979 - val_categorical_accuracy: 0.8781 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2017 - categorical_accuracy: 0.9308\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 30: categorical_accuracy did not improve from 0.93294\n",
      "178/178 [==============================] - 140s 787ms/step - loss: 0.2017 - categorical_accuracy: 0.9308 - val_loss: 0.8262 - val_categorical_accuracy: 0.7828 - lr: 2.0000e-04\n",
      "Epoch 31/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1662 - categorical_accuracy: 0.9386\n",
      "Epoch 31: categorical_accuracy improved from 0.93294 to 0.93855, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 153s 858ms/step - loss: 0.1662 - categorical_accuracy: 0.9386 - val_loss: 0.2410 - val_categorical_accuracy: 0.9187 - lr: 4.0000e-05\n",
      "Epoch 32/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1341 - categorical_accuracy: 0.9582\n",
      "Epoch 32: categorical_accuracy improved from 0.93855 to 0.95822, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 157s 880ms/step - loss: 0.1341 - categorical_accuracy: 0.9582 - val_loss: 0.2873 - val_categorical_accuracy: 0.9062 - lr: 4.0000e-05\n",
      "Epoch 33/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1458 - categorical_accuracy: 0.9522\n",
      "Epoch 33: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 141s 790ms/step - loss: 0.1458 - categorical_accuracy: 0.9522 - val_loss: 0.2199 - val_categorical_accuracy: 0.9141 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1487 - categorical_accuracy: 0.9431\n",
      "Epoch 34: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 140s 788ms/step - loss: 0.1487 - categorical_accuracy: 0.9431 - val_loss: 0.2324 - val_categorical_accuracy: 0.9156 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1295 - categorical_accuracy: 0.9561\n",
      "Epoch 35: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 142s 795ms/step - loss: 0.1295 - categorical_accuracy: 0.9561 - val_loss: 0.2496 - val_categorical_accuracy: 0.9172 - lr: 4.0000e-05\n",
      "Epoch 36/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1367 - categorical_accuracy: 0.9501\n",
      "Epoch 36: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 142s 799ms/step - loss: 0.1367 - categorical_accuracy: 0.9501 - val_loss: 0.2041 - val_categorical_accuracy: 0.9297 - lr: 4.0000e-05\n",
      "Epoch 37/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1321 - categorical_accuracy: 0.9554\n",
      "Epoch 37: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 142s 797ms/step - loss: 0.1321 - categorical_accuracy: 0.9554 - val_loss: 0.2224 - val_categorical_accuracy: 0.9266 - lr: 4.0000e-05\n",
      "Epoch 38/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1310 - categorical_accuracy: 0.9554\n",
      "Epoch 38: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 142s 798ms/step - loss: 0.1310 - categorical_accuracy: 0.9554 - val_loss: 0.2135 - val_categorical_accuracy: 0.9203 - lr: 4.0000e-05\n",
      "Epoch 39/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1285 - categorical_accuracy: 0.9512\n",
      "Epoch 39: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 142s 797ms/step - loss: 0.1285 - categorical_accuracy: 0.9512 - val_loss: 0.1928 - val_categorical_accuracy: 0.9297 - lr: 4.0000e-05\n",
      "Epoch 40/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1382 - categorical_accuracy: 0.9473\n",
      "Epoch 40: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 141s 789ms/step - loss: 0.1382 - categorical_accuracy: 0.9473 - val_loss: 0.1768 - val_categorical_accuracy: 0.9344 - lr: 4.0000e-05\n",
      "Epoch 41/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1198 - categorical_accuracy: 0.9589\n",
      "Epoch 41: categorical_accuracy improved from 0.95822 to 0.95892, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 153s 861ms/step - loss: 0.1198 - categorical_accuracy: 0.9589 - val_loss: 0.2731 - val_categorical_accuracy: 0.9016 - lr: 4.0000e-05\n",
      "Epoch 42/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1284 - categorical_accuracy: 0.9540\n",
      "Epoch 42: categorical_accuracy did not improve from 0.95892\n",
      "178/178 [==============================] - 142s 797ms/step - loss: 0.1284 - categorical_accuracy: 0.9540 - val_loss: 0.1936 - val_categorical_accuracy: 0.9359 - lr: 4.0000e-05\n",
      "Epoch 43/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1118 - categorical_accuracy: 0.9617\n",
      "Epoch 43: categorical_accuracy improved from 0.95892 to 0.96173, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 153s 858ms/step - loss: 0.1118 - categorical_accuracy: 0.9617 - val_loss: 0.2052 - val_categorical_accuracy: 0.9203 - lr: 4.0000e-05\n",
      "Epoch 44/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1207 - categorical_accuracy: 0.9572\n",
      "Epoch 44: categorical_accuracy did not improve from 0.96173\n",
      "178/178 [==============================] - 141s 789ms/step - loss: 0.1207 - categorical_accuracy: 0.9572 - val_loss: 0.2097 - val_categorical_accuracy: 0.9297 - lr: 4.0000e-05\n",
      "Epoch 45/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1222 - categorical_accuracy: 0.9540\n",
      "Epoch 45: categorical_accuracy did not improve from 0.96173\n",
      "178/178 [==============================] - 141s 791ms/step - loss: 0.1222 - categorical_accuracy: 0.9540 - val_loss: 0.1830 - val_categorical_accuracy: 0.9344 - lr: 4.0000e-05\n",
      "Epoch 46/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1122 - categorical_accuracy: 0.9579\n",
      "Epoch 46: categorical_accuracy did not improve from 0.96173\n",
      "178/178 [==============================] - 141s 791ms/step - loss: 0.1122 - categorical_accuracy: 0.9579 - val_loss: 0.1407 - val_categorical_accuracy: 0.9484 - lr: 4.0000e-05\n",
      "Epoch 47/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1053 - categorical_accuracy: 0.9638\n",
      "Epoch 47: categorical_accuracy improved from 0.96173 to 0.96383, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 154s 863ms/step - loss: 0.1053 - categorical_accuracy: 0.9638 - val_loss: 0.1874 - val_categorical_accuracy: 0.9438 - lr: 4.0000e-05\n",
      "Epoch 48/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1102 - categorical_accuracy: 0.9603\n",
      "Epoch 48: categorical_accuracy did not improve from 0.96383\n",
      "178/178 [==============================] - 142s 796ms/step - loss: 0.1102 - categorical_accuracy: 0.9603 - val_loss: 0.2148 - val_categorical_accuracy: 0.9375 - lr: 4.0000e-05\n",
      "Epoch 49/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1090 - categorical_accuracy: 0.9596\n",
      "Epoch 49: categorical_accuracy did not improve from 0.96383\n",
      "178/178 [==============================] - 142s 797ms/step - loss: 0.1090 - categorical_accuracy: 0.9596 - val_loss: 0.2397 - val_categorical_accuracy: 0.9187 - lr: 4.0000e-05\n",
      "Epoch 50/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1066 - categorical_accuracy: 0.9614\n",
      "Epoch 50: categorical_accuracy did not improve from 0.96383\n",
      "178/178 [==============================] - 142s 796ms/step - loss: 0.1066 - categorical_accuracy: 0.9614 - val_loss: 0.1489 - val_categorical_accuracy: 0.9453 - lr: 4.0000e-05\n",
      "Epoch 51/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0977 - categorical_accuracy: 0.9652\n",
      "Epoch 51: categorical_accuracy improved from 0.96383 to 0.96524, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 152s 856ms/step - loss: 0.0977 - categorical_accuracy: 0.9652 - val_loss: 0.1663 - val_categorical_accuracy: 0.9297 - lr: 4.0000e-05\n",
      "Epoch 52/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0889 - categorical_accuracy: 0.9705\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 52: categorical_accuracy improved from 0.96524 to 0.97051, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 153s 858ms/step - loss: 0.0889 - categorical_accuracy: 0.9705 - val_loss: 0.2355 - val_categorical_accuracy: 0.9297 - lr: 4.0000e-05\n",
      "Epoch 53/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1014 - categorical_accuracy: 0.9649\n",
      "Epoch 53: categorical_accuracy did not improve from 0.97051\n",
      "178/178 [==============================] - 142s 796ms/step - loss: 0.1014 - categorical_accuracy: 0.9649 - val_loss: 0.1557 - val_categorical_accuracy: 0.9469 - lr: 8.0000e-06\n",
      "Epoch 54/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0946 - categorical_accuracy: 0.9656\n",
      "Epoch 54: categorical_accuracy did not improve from 0.97051\n",
      "178/178 [==============================] - 143s 800ms/step - loss: 0.0946 - categorical_accuracy: 0.9656 - val_loss: 0.2089 - val_categorical_accuracy: 0.9328 - lr: 8.0000e-06\n",
      "Epoch 55/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0882 - categorical_accuracy: 0.9670\n",
      "Epoch 55: categorical_accuracy did not improve from 0.97051\n",
      "178/178 [==============================] - 142s 799ms/step - loss: 0.0882 - categorical_accuracy: 0.9670 - val_loss: 0.1336 - val_categorical_accuracy: 0.9563 - lr: 8.0000e-06\n",
      "Epoch 56/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0800 - categorical_accuracy: 0.9705\n",
      "Epoch 56: categorical_accuracy did not improve from 0.97051\n",
      "178/178 [==============================] - 142s 799ms/step - loss: 0.0800 - categorical_accuracy: 0.9705 - val_loss: 0.1229 - val_categorical_accuracy: 0.9578 - lr: 8.0000e-06\n",
      "Epoch 57/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0914 - categorical_accuracy: 0.9691\n",
      "Epoch 57: categorical_accuracy did not improve from 0.97051\n",
      "178/178 [==============================] - 144s 806ms/step - loss: 0.0914 - categorical_accuracy: 0.9691 - val_loss: 0.1727 - val_categorical_accuracy: 0.9578 - lr: 8.0000e-06\n",
      "Epoch 58/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0929 - categorical_accuracy: 0.9691\n",
      "Epoch 58: categorical_accuracy did not improve from 0.97051\n",
      "178/178 [==============================] - 144s 806ms/step - loss: 0.0929 - categorical_accuracy: 0.9691 - val_loss: 0.1087 - val_categorical_accuracy: 0.9625 - lr: 8.0000e-06\n",
      "Epoch 59/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0879 - categorical_accuracy: 0.9691\n",
      "Epoch 59: categorical_accuracy did not improve from 0.97051\n",
      "178/178 [==============================] - 143s 805ms/step - loss: 0.0879 - categorical_accuracy: 0.9691 - val_loss: 0.1596 - val_categorical_accuracy: 0.9438 - lr: 8.0000e-06\n",
      "Epoch 60/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0916 - categorical_accuracy: 0.9709\n",
      "Epoch 60: categorical_accuracy improved from 0.97051 to 0.97086, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 155s 871ms/step - loss: 0.0916 - categorical_accuracy: 0.9709 - val_loss: 0.1423 - val_categorical_accuracy: 0.9578 - lr: 8.0000e-06\n",
      "Epoch 61/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0946 - categorical_accuracy: 0.9680\n",
      "Epoch 61: categorical_accuracy did not improve from 0.97086\n",
      "178/178 [==============================] - 143s 800ms/step - loss: 0.0946 - categorical_accuracy: 0.9680 - val_loss: 0.1594 - val_categorical_accuracy: 0.9375 - lr: 8.0000e-06\n",
      "Epoch 62/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0800 - categorical_accuracy: 0.9712\n",
      "Epoch 62: categorical_accuracy improved from 0.97086 to 0.97121, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 155s 871ms/step - loss: 0.0800 - categorical_accuracy: 0.9712 - val_loss: 0.1126 - val_categorical_accuracy: 0.9594 - lr: 8.0000e-06\n",
      "Epoch 63/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1032 - categorical_accuracy: 0.9621\n",
      "Epoch 63: categorical_accuracy did not improve from 0.97121\n",
      "178/178 [==============================] - 143s 801ms/step - loss: 0.1032 - categorical_accuracy: 0.9621 - val_loss: 0.1363 - val_categorical_accuracy: 0.9547 - lr: 8.0000e-06\n",
      "Epoch 64/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0831 - categorical_accuracy: 0.9702\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 64: categorical_accuracy did not improve from 0.97121\n",
      "178/178 [==============================] - 141s 793ms/step - loss: 0.0831 - categorical_accuracy: 0.9702 - val_loss: 0.1503 - val_categorical_accuracy: 0.9516 - lr: 8.0000e-06\n",
      "Epoch 65/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0854 - categorical_accuracy: 0.9712\n",
      "Epoch 65: categorical_accuracy did not improve from 0.97121\n",
      "178/178 [==============================] - 141s 793ms/step - loss: 0.0854 - categorical_accuracy: 0.9712 - val_loss: 0.1004 - val_categorical_accuracy: 0.9594 - lr: 1.6000e-06\n",
      "Epoch 66/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0885 - categorical_accuracy: 0.9712\n",
      "Epoch 66: categorical_accuracy did not improve from 0.97121\n",
      "178/178 [==============================] - 142s 796ms/step - loss: 0.0885 - categorical_accuracy: 0.9712 - val_loss: 0.1669 - val_categorical_accuracy: 0.9422 - lr: 1.6000e-06\n",
      "Epoch 67/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0855 - categorical_accuracy: 0.9688\n",
      "Epoch 67: categorical_accuracy did not improve from 0.97121\n",
      "178/178 [==============================] - 141s 794ms/step - loss: 0.0855 - categorical_accuracy: 0.9688 - val_loss: 0.1189 - val_categorical_accuracy: 0.9594 - lr: 1.6000e-06\n",
      "Epoch 68/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0678 - categorical_accuracy: 0.9768\n",
      "Epoch 68: categorical_accuracy improved from 0.97121 to 0.97683, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 153s 860ms/step - loss: 0.0678 - categorical_accuracy: 0.9768 - val_loss: 0.1207 - val_categorical_accuracy: 0.9594 - lr: 1.6000e-06\n",
      "Epoch 69/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0913 - categorical_accuracy: 0.9656\n",
      "Epoch 69: categorical_accuracy did not improve from 0.97683\n",
      "178/178 [==============================] - 141s 791ms/step - loss: 0.0913 - categorical_accuracy: 0.9656 - val_loss: 0.1286 - val_categorical_accuracy: 0.9578 - lr: 1.6000e-06\n",
      "Epoch 70/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0835 - categorical_accuracy: 0.9782\n",
      "Epoch 70: categorical_accuracy improved from 0.97683 to 0.97823, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 153s 860ms/step - loss: 0.0835 - categorical_accuracy: 0.9782 - val_loss: 0.1596 - val_categorical_accuracy: 0.9516 - lr: 1.6000e-06\n",
      "Epoch 71/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0895 - categorical_accuracy: 0.9716\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 71: categorical_accuracy did not improve from 0.97823\n",
      "178/178 [==============================] - 142s 798ms/step - loss: 0.0895 - categorical_accuracy: 0.9716 - val_loss: 0.1221 - val_categorical_accuracy: 0.9609 - lr: 1.6000e-06\n",
      "Epoch 72/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0763 - categorical_accuracy: 0.9765\n",
      "Epoch 72: categorical_accuracy did not improve from 0.97823\n",
      "178/178 [==============================] - 141s 794ms/step - loss: 0.0763 - categorical_accuracy: 0.9765 - val_loss: 0.1402 - val_categorical_accuracy: 0.9422 - lr: 3.2000e-07\n",
      "Epoch 73/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0794 - categorical_accuracy: 0.9705\n",
      "Epoch 73: categorical_accuracy did not improve from 0.97823\n",
      "178/178 [==============================] - 141s 794ms/step - loss: 0.0794 - categorical_accuracy: 0.9705 - val_loss: 0.1282 - val_categorical_accuracy: 0.9578 - lr: 3.2000e-07\n",
      "Epoch 74/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0832 - categorical_accuracy: 0.9688\n",
      "Epoch 74: categorical_accuracy did not improve from 0.97823\n",
      "178/178 [==============================] - 143s 803ms/step - loss: 0.0832 - categorical_accuracy: 0.9688 - val_loss: 0.1392 - val_categorical_accuracy: 0.9453 - lr: 3.2000e-07\n",
      "Epoch 75/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0766 - categorical_accuracy: 0.9730\n",
      "Epoch 75: categorical_accuracy did not improve from 0.97823\n",
      "178/178 [==============================] - 141s 794ms/step - loss: 0.0766 - categorical_accuracy: 0.9730 - val_loss: 0.1438 - val_categorical_accuracy: 0.9453 - lr: 3.2000e-07\n",
      "Epoch 76/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0866 - categorical_accuracy: 0.9695\n",
      "Epoch 76: categorical_accuracy did not improve from 0.97823\n",
      "178/178 [==============================] - 141s 794ms/step - loss: 0.0866 - categorical_accuracy: 0.9695 - val_loss: 0.1358 - val_categorical_accuracy: 0.9531 - lr: 3.2000e-07\n",
      "Epoch 77/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0898 - categorical_accuracy: 0.9684\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 77: categorical_accuracy did not improve from 0.97823\n",
      "178/178 [==============================] - 142s 795ms/step - loss: 0.0898 - categorical_accuracy: 0.9684 - val_loss: 0.1313 - val_categorical_accuracy: 0.9516 - lr: 3.2000e-07\n",
      "Epoch 78/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0760 - categorical_accuracy: 0.9705\n",
      "Epoch 78: categorical_accuracy did not improve from 0.97823\n",
      "178/178 [==============================] - 144s 807ms/step - loss: 0.0760 - categorical_accuracy: 0.9705 - val_loss: 0.1488 - val_categorical_accuracy: 0.9500 - lr: 6.4000e-08\n",
      "Epoch 79/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0905 - categorical_accuracy: 0.9719\n",
      "Epoch 79: categorical_accuracy did not improve from 0.97823\n",
      "178/178 [==============================] - 143s 801ms/step - loss: 0.0905 - categorical_accuracy: 0.9719 - val_loss: 0.1540 - val_categorical_accuracy: 0.9453 - lr: 6.4000e-08\n",
      "Epoch 80/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0802 - categorical_accuracy: 0.9733\n",
      "Epoch 80: categorical_accuracy did not improve from 0.97823\n",
      "178/178 [==============================] - 143s 802ms/step - loss: 0.0802 - categorical_accuracy: 0.9733 - val_loss: 0.1303 - val_categorical_accuracy: 0.9594 - lr: 6.4000e-08\n",
      "Epoch 80: early stopping\n"
     ]
    }
   ],
   "source": [
    "ResNet_conv = ResNet152V2(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in ResNet_conv.layers[-7:]:\n",
    "    layer.trainable = False    \n",
    "\n",
    "resnet_feedforword = Flatten()(ResNet_conv.output)\n",
    "\n",
    "prediction = Dense(len(folders), activation='softmax')(resnet_feedforword)\n",
    "\n",
    "model_ResNet = Model(inputs= ResNet_conv.input, outputs=prediction)\n",
    "\n",
    "model_ResNet.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "model1_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model1_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "model1_mcp = ModelCheckpoint(filepath = r'temp\\model1_weights.h5', monitor = 'categorical_accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n",
    "model_ResNet_fit = model_ResNet.fit(\n",
    "  train,\n",
    "  validation_data=test,\n",
    "  epochs=100,\n",
    "  steps_per_epoch=5712//32,\n",
    "  validation_steps=1311//32,\n",
    "  callbacks=[model1_es, model1_rlr, model1_mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('models/resnet152_2conv_train.h5') is False:\n",
    "    model_ResNet.save('models/resnet152_2conv_train.h5')\n",
    "    \n",
    "resnet152_2conv_trained = load_model('models/resnet152_2conv_train.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6 - InceptionV3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 6s 0us/step\n",
      "Epoch 1/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 15.0154 - categorical_accuracy: 0.7051\n",
      "Epoch 1: categorical_accuracy improved from -inf to 0.70506, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 110s 563ms/step - loss: 15.0154 - categorical_accuracy: 0.7051 - val_loss: 2.9590 - val_categorical_accuracy: 0.8047 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.6660 - categorical_accuracy: 0.8097\n",
      "Epoch 2: categorical_accuracy improved from 0.70506 to 0.80969, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 72s 404ms/step - loss: 1.6660 - categorical_accuracy: 0.8097 - val_loss: 0.7484 - val_categorical_accuracy: 0.8234 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.9642 - categorical_accuracy: 0.8065\n",
      "Epoch 3: categorical_accuracy did not improve from 0.80969\n",
      "178/178 [==============================] - 53s 297ms/step - loss: 0.9642 - categorical_accuracy: 0.8065 - val_loss: 0.6276 - val_categorical_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.7817 - categorical_accuracy: 0.8438\n",
      "Epoch 4: categorical_accuracy improved from 0.80969 to 0.84375, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 54s 305ms/step - loss: 0.7817 - categorical_accuracy: 0.8438 - val_loss: 0.3516 - val_categorical_accuracy: 0.8844 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.5111 - categorical_accuracy: 0.8704\n",
      "Epoch 5: categorical_accuracy improved from 0.84375 to 0.87044, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 53s 295ms/step - loss: 0.5111 - categorical_accuracy: 0.8704 - val_loss: 0.7311 - val_categorical_accuracy: 0.8203 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4693 - categorical_accuracy: 0.8715\n",
      "Epoch 6: categorical_accuracy improved from 0.87044 to 0.87149, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 50s 278ms/step - loss: 0.4693 - categorical_accuracy: 0.8715 - val_loss: 0.7907 - val_categorical_accuracy: 0.8078 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4885 - categorical_accuracy: 0.8904\n",
      "Epoch 7: categorical_accuracy improved from 0.87149 to 0.89045, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 52s 290ms/step - loss: 0.4885 - categorical_accuracy: 0.8904 - val_loss: 0.7365 - val_categorical_accuracy: 0.8453 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4264 - categorical_accuracy: 0.9020\n",
      "Epoch 8: categorical_accuracy improved from 0.89045 to 0.90204, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 53s 295ms/step - loss: 0.4264 - categorical_accuracy: 0.9020 - val_loss: 0.4998 - val_categorical_accuracy: 0.8516 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3605 - categorical_accuracy: 0.9073\n",
      "Epoch 9: categorical_accuracy improved from 0.90204 to 0.90730, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 50s 281ms/step - loss: 0.3605 - categorical_accuracy: 0.9073 - val_loss: 0.7787 - val_categorical_accuracy: 0.8219 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4779 - categorical_accuracy: 0.9010\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 10: categorical_accuracy did not improve from 0.90730\n",
      "178/178 [==============================] - 46s 256ms/step - loss: 0.4779 - categorical_accuracy: 0.9010 - val_loss: 0.7936 - val_categorical_accuracy: 0.8656 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2131 - categorical_accuracy: 0.9410\n",
      "Epoch 11: categorical_accuracy improved from 0.90730 to 0.94101, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 325ms/step - loss: 0.2131 - categorical_accuracy: 0.9410 - val_loss: 0.2508 - val_categorical_accuracy: 0.9156 - lr: 2.0000e-04\n",
      "Epoch 12/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1432 - categorical_accuracy: 0.9551\n",
      "Epoch 12: categorical_accuracy improved from 0.94101 to 0.95506, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 59s 329ms/step - loss: 0.1432 - categorical_accuracy: 0.9551 - val_loss: 0.1975 - val_categorical_accuracy: 0.9391 - lr: 2.0000e-04\n",
      "Epoch 13/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1312 - categorical_accuracy: 0.9572\n",
      "Epoch 13: categorical_accuracy improved from 0.95506 to 0.95716, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 54s 305ms/step - loss: 0.1312 - categorical_accuracy: 0.9572 - val_loss: 0.2458 - val_categorical_accuracy: 0.9109 - lr: 2.0000e-04\n",
      "Epoch 14/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1318 - categorical_accuracy: 0.9614\n",
      "Epoch 14: categorical_accuracy improved from 0.95716 to 0.96138, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 56s 316ms/step - loss: 0.1318 - categorical_accuracy: 0.9614 - val_loss: 0.2300 - val_categorical_accuracy: 0.9312 - lr: 2.0000e-04\n",
      "Epoch 15/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1085 - categorical_accuracy: 0.9638\n",
      "Epoch 15: categorical_accuracy improved from 0.96138 to 0.96383, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 51s 284ms/step - loss: 0.1085 - categorical_accuracy: 0.9638 - val_loss: 0.2078 - val_categorical_accuracy: 0.9375 - lr: 2.0000e-04\n",
      "Epoch 16/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0967 - categorical_accuracy: 0.9691\n",
      "Epoch 16: categorical_accuracy improved from 0.96383 to 0.96910, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 50s 280ms/step - loss: 0.0967 - categorical_accuracy: 0.9691 - val_loss: 0.2349 - val_categorical_accuracy: 0.9422 - lr: 2.0000e-04\n",
      "Epoch 17/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1125 - categorical_accuracy: 0.9649\n",
      "Epoch 17: categorical_accuracy did not improve from 0.96910\n",
      "178/178 [==============================] - 44s 248ms/step - loss: 0.1125 - categorical_accuracy: 0.9649 - val_loss: 0.1924 - val_categorical_accuracy: 0.9328 - lr: 2.0000e-04\n",
      "Epoch 18/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0892 - categorical_accuracy: 0.9737\n",
      "Epoch 18: categorical_accuracy improved from 0.96910 to 0.97367, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 51s 284ms/step - loss: 0.0892 - categorical_accuracy: 0.9737 - val_loss: 0.2574 - val_categorical_accuracy: 0.9281 - lr: 2.0000e-04\n",
      "Epoch 19/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0852 - categorical_accuracy: 0.9751\n",
      "Epoch 19: categorical_accuracy improved from 0.97367 to 0.97507, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 50s 282ms/step - loss: 0.0852 - categorical_accuracy: 0.9751 - val_loss: 0.1902 - val_categorical_accuracy: 0.9406 - lr: 2.0000e-04\n",
      "Epoch 20/20\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0948 - categorical_accuracy: 0.9695\n",
      "Epoch 20: categorical_accuracy did not improve from 0.97507\n",
      "178/178 [==============================] - 48s 271ms/step - loss: 0.0948 - categorical_accuracy: 0.9695 - val_loss: 0.1624 - val_categorical_accuracy: 0.9422 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "inception_conv = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in inception_conv.layers:\n",
    "    layer.trainable = False    \n",
    "\n",
    "inception_feedforword = Flatten()(inception_conv.output)\n",
    "inception_feedforword = Dense(1024,activation = 'relu')(inception_feedforword)\n",
    "\n",
    "prediction = Dense(len(folders), activation='softmax')(inception_feedforword)\n",
    "\n",
    "model_inception = Model(inputs= inception_conv.input, outputs=prediction)\n",
    "\n",
    "model_inception.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='RMSprop',\n",
    "  metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "model1_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model1_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "model1_mcp = ModelCheckpoint(filepath = r'temp\\model1_weights.h5', monitor = 'categorical_accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n",
    "model_inception_fit = model_inception.fit(\n",
    "  train,\n",
    "  validation_data=test,\n",
    "  epochs=20,\n",
    "  steps_per_epoch=5712//32,\n",
    "  validation_steps=1311//32,\n",
    "  callbacks=[model1_es, model1_rlr, model1_mcp])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('tf2.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "927d683070d8f87e257ecab0c999e91a9159e1dddb39dd14b355c9356536362e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
