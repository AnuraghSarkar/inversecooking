{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import os.path\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import operator\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pylab as pl\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   \n",
    "from IPython.display import Image, display\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs: ', len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predictions Dataframe Initialisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_images(paths):\n",
    "    '''\n",
    "    Opens a batch of images, given the image path(s) as a list\n",
    "    '''\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        image = load_img(path, target_size=(224,224))\n",
    "        image = np.array(image)/255.0\n",
    "        images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "def get_labels(paths):\n",
    "    '''\n",
    "    it is possible to get the label from the path, just split the path by \"/\" and index -2\n",
    "    For example, /kaggle/input/brain-tumor-mri-dataset/Training/pituitary/Tr-pi_1020.jpg\n",
    "    splitting by \"/\" gives ['kaggle','input','brain-tumor-mri-dataset','Training','pituitary','Tr-pi_1020.jpg']\n",
    "    Now indexing -2 gives \"pituitary\"\n",
    "    '''\n",
    "    label = []\n",
    "    for path in paths:\n",
    "        path = path.split('/')[-2]\n",
    "        label.append(labels.index(path))\n",
    "    return label\n",
    "\n",
    "train_dir = r'Training/'\n",
    "test_dir = r'Testing/'\n",
    "\n",
    "train_paths = []\n",
    "test_paths = []\n",
    "\n",
    "\n",
    "for label in os.listdir(train_dir):\n",
    "    for file in os.listdir(train_dir+label):\n",
    "        train_paths.append(train_dir+label+'/'+file)\n",
    "\n",
    "\n",
    "for label in os.listdir(test_dir):\n",
    "    for file in os.listdir(test_dir+label):\n",
    "        test_paths.append(test_dir+label+'/'+file)\n",
    "\n",
    "labels_test = os.listdir(test_dir)\n",
    "labels_train = os.listdir(train_dir)\n",
    "\n",
    "model_predictions_train = pd.DataFrame(columns = ['3c2f','vgg16','vgg16_ctrained','resnet','resnet_ctrained','inception','inception_ctrained','actual'], \n",
    "                                       index = train_paths ).fillna('here')\n",
    "\n",
    "model_predictions_test = pd.DataFrame(columns = ['3c2f','vgg16','vgg16_ctrained','resnet','resnet_ctrained','inception','inception_ctrained','actual'], \n",
    "                                       index = test_paths ).fillna('here')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Augmenting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5712 images belonging to 4 classes.\n",
      "Found 1311 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "generator_train = ImageDataGenerator(rescale=1/255,\n",
    "                                     rotation_range=7,\n",
    "                                     horizontal_flip=True,\n",
    "                                     shear_range=0.1,\n",
    "                                     height_shift_range=0.07,\n",
    "                                     zoom_range=0.1)\n",
    "\n",
    "\n",
    "train = generator_train.flow_from_directory(r'Training', target_size=(224,224), # height and width of images to feed into CNN\n",
    "                                              batch_size=16, class_mode= \"categorical\", color_mode='rgb')\n",
    "\n",
    "\n",
    "generator_test = ImageDataGenerator(rescale=1/255,\n",
    "                                     rotation_range=7,\n",
    "                                     horizontal_flip=True,\n",
    "                                     shear_range=0.1,\n",
    "                                     height_shift_range=0.07,\n",
    "                                     zoom_range=0.1)\n",
    "\n",
    "\n",
    "test = generator_test.flow_from_directory(r'Testing', target_size=(224,224),\n",
    "                                              batch_size=16, class_mode= \"categorical\", color_mode='rgb')\n",
    "\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = r'Training'\n",
    "valid_path = r'Testing'\n",
    "\n",
    "folders = glob(r'Training/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predictions Dataframe Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 5.9762 - categorical_accuracy: 0.5706\n",
      "Epoch 1: categorical_accuracy improved from -inf to 0.57055, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 192s 535ms/step - loss: 5.9762 - categorical_accuracy: 0.5706 - val_loss: 5.8169 - val_categorical_accuracy: 0.3843 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 1.3751 - categorical_accuracy: 0.5420\n",
      "Epoch 2: categorical_accuracy did not improve from 0.57055\n",
      "357/357 [==============================] - 100s 279ms/step - loss: 1.3751 - categorical_accuracy: 0.5420 - val_loss: 1.3173 - val_categorical_accuracy: 0.4838 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 1.1921 - categorical_accuracy: 0.5368\n",
      "Epoch 3: categorical_accuracy did not improve from 0.57055\n",
      "357/357 [==============================] - 95s 265ms/step - loss: 1.1921 - categorical_accuracy: 0.5368 - val_loss: 1.2638 - val_categorical_accuracy: 0.4128 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 1.1513 - categorical_accuracy: 0.5399\n",
      "Epoch 4: categorical_accuracy did not improve from 0.57055\n",
      "357/357 [==============================] - 96s 267ms/step - loss: 1.1513 - categorical_accuracy: 0.5399 - val_loss: 2.1272 - val_categorical_accuracy: 0.6466 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 1.0826 - categorical_accuracy: 0.5854\n",
      "Epoch 5: categorical_accuracy improved from 0.57055 to 0.58543, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 101s 282ms/step - loss: 1.0826 - categorical_accuracy: 0.5854 - val_loss: 1.5508 - val_categorical_accuracy: 0.5802 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 1.0852 - categorical_accuracy: 0.5777\n",
      "Epoch 6: categorical_accuracy did not improve from 0.58543\n",
      "357/357 [==============================] - 95s 265ms/step - loss: 1.0852 - categorical_accuracy: 0.5777 - val_loss: 0.8309 - val_categorical_accuracy: 0.6636 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.9625 - categorical_accuracy: 0.6101\n",
      "Epoch 7: categorical_accuracy improved from 0.58543 to 0.61012, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 99s 276ms/step - loss: 0.9625 - categorical_accuracy: 0.6101 - val_loss: 0.9136 - val_categorical_accuracy: 0.6427 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.9291 - categorical_accuracy: 0.6239\n",
      "Epoch 8: categorical_accuracy improved from 0.61012 to 0.62395, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 98s 273ms/step - loss: 0.9291 - categorical_accuracy: 0.6239 - val_loss: 1.0848 - val_categorical_accuracy: 0.6775 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.8708 - categorical_accuracy: 0.6464\n",
      "Epoch 9: categorical_accuracy improved from 0.62395 to 0.64636, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 100s 279ms/step - loss: 0.8708 - categorical_accuracy: 0.6464 - val_loss: 0.8061 - val_categorical_accuracy: 0.6836 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.7808 - categorical_accuracy: 0.6667\n",
      "Epoch 10: categorical_accuracy improved from 0.64636 to 0.66667, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 98s 274ms/step - loss: 0.7808 - categorical_accuracy: 0.6667 - val_loss: 0.8627 - val_categorical_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.8039 - categorical_accuracy: 0.6658\n",
      "Epoch 11: categorical_accuracy did not improve from 0.66667\n",
      "357/357 [==============================] - 92s 256ms/step - loss: 0.8039 - categorical_accuracy: 0.6658 - val_loss: 0.8084 - val_categorical_accuracy: 0.6412 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.7404 - categorical_accuracy: 0.6777\n",
      "Epoch 12: categorical_accuracy improved from 0.66667 to 0.67770, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 92s 258ms/step - loss: 0.7404 - categorical_accuracy: 0.6777 - val_loss: 0.7181 - val_categorical_accuracy: 0.7230 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.7204 - categorical_accuracy: 0.6884\n",
      "Epoch 13: categorical_accuracy improved from 0.67770 to 0.68838, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 97s 272ms/step - loss: 0.7204 - categorical_accuracy: 0.6884 - val_loss: 0.8020 - val_categorical_accuracy: 0.7083 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.7425 - categorical_accuracy: 0.6929\n",
      "Epoch 14: categorical_accuracy improved from 0.68838 to 0.69293, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 92s 258ms/step - loss: 0.7425 - categorical_accuracy: 0.6929 - val_loss: 0.8072 - val_categorical_accuracy: 0.7037 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.6913 - categorical_accuracy: 0.6970\n",
      "Epoch 15: categorical_accuracy improved from 0.69293 to 0.69695, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 93s 260ms/step - loss: 0.6913 - categorical_accuracy: 0.6970 - val_loss: 0.7418 - val_categorical_accuracy: 0.7269 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.6481 - categorical_accuracy: 0.7047\n",
      "Epoch 16: categorical_accuracy improved from 0.69695 to 0.70466, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 94s 263ms/step - loss: 0.6481 - categorical_accuracy: 0.7047 - val_loss: 0.7178 - val_categorical_accuracy: 0.7515 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.6524 - categorical_accuracy: 0.7054\n",
      "Epoch 17: categorical_accuracy improved from 0.70466 to 0.70536, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 92s 258ms/step - loss: 0.6524 - categorical_accuracy: 0.7054 - val_loss: 0.8098 - val_categorical_accuracy: 0.7346 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.6683 - categorical_accuracy: 0.7134\n",
      "Epoch 18: categorical_accuracy improved from 0.70536 to 0.71341, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 93s 261ms/step - loss: 0.6683 - categorical_accuracy: 0.7134 - val_loss: 0.8866 - val_categorical_accuracy: 0.6937 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.6199 - categorical_accuracy: 0.7197\n",
      "Epoch 19: categorical_accuracy improved from 0.71341 to 0.71971, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 93s 261ms/step - loss: 0.6199 - categorical_accuracy: 0.7197 - val_loss: 0.8433 - val_categorical_accuracy: 0.6458 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.6428 - categorical_accuracy: 0.7090\n",
      "Epoch 20: categorical_accuracy did not improve from 0.71971\n",
      "357/357 [==============================] - 87s 244ms/step - loss: 0.6428 - categorical_accuracy: 0.7090 - val_loss: 0.5930 - val_categorical_accuracy: 0.7469 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.6165 - categorical_accuracy: 0.7187\n",
      "Epoch 21: categorical_accuracy did not improve from 0.71971\n",
      "357/357 [==============================] - 96s 268ms/step - loss: 0.6165 - categorical_accuracy: 0.7187 - val_loss: 0.6268 - val_categorical_accuracy: 0.7299 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.6003 - categorical_accuracy: 0.7286\n",
      "Epoch 22: categorical_accuracy improved from 0.71971 to 0.72864, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 107s 299ms/step - loss: 0.6003 - categorical_accuracy: 0.7286 - val_loss: 0.5934 - val_categorical_accuracy: 0.7515 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5919 - categorical_accuracy: 0.7269\n",
      "Epoch 23: categorical_accuracy did not improve from 0.72864\n",
      "357/357 [==============================] - 97s 272ms/step - loss: 0.5919 - categorical_accuracy: 0.7269 - val_loss: 0.5991 - val_categorical_accuracy: 0.7407 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5832 - categorical_accuracy: 0.7218\n",
      "Epoch 24: categorical_accuracy did not improve from 0.72864\n",
      "357/357 [==============================] - 92s 258ms/step - loss: 0.5832 - categorical_accuracy: 0.7218 - val_loss: 0.5518 - val_categorical_accuracy: 0.7554 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5885 - categorical_accuracy: 0.7265\n",
      "Epoch 25: categorical_accuracy did not improve from 0.72864\n",
      "357/357 [==============================] - 92s 256ms/step - loss: 0.5885 - categorical_accuracy: 0.7265 - val_loss: 0.5806 - val_categorical_accuracy: 0.7639 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5679 - categorical_accuracy: 0.7360\n",
      "Epoch 26: categorical_accuracy improved from 0.72864 to 0.73599, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 96s 269ms/step - loss: 0.5679 - categorical_accuracy: 0.7360 - val_loss: 0.5743 - val_categorical_accuracy: 0.7677 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5522 - categorical_accuracy: 0.7327\n",
      "Epoch 27: categorical_accuracy did not improve from 0.73599\n",
      "357/357 [==============================] - 101s 283ms/step - loss: 0.5522 - categorical_accuracy: 0.7327 - val_loss: 0.5687 - val_categorical_accuracy: 0.7569 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5494 - categorical_accuracy: 0.7409\n",
      "Epoch 28: categorical_accuracy improved from 0.73599 to 0.74090, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 99s 277ms/step - loss: 0.5494 - categorical_accuracy: 0.7409 - val_loss: 0.5272 - val_categorical_accuracy: 0.7585 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5476 - categorical_accuracy: 0.7337\n",
      "Epoch 29: categorical_accuracy did not improve from 0.74090\n",
      "357/357 [==============================] - 100s 279ms/step - loss: 0.5476 - categorical_accuracy: 0.7337 - val_loss: 0.5933 - val_categorical_accuracy: 0.7623 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5365 - categorical_accuracy: 0.7384\n",
      "Epoch 30: categorical_accuracy did not improve from 0.74090\n",
      "357/357 [==============================] - 98s 275ms/step - loss: 0.5365 - categorical_accuracy: 0.7384 - val_loss: 0.6387 - val_categorical_accuracy: 0.7739 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5180 - categorical_accuracy: 0.7484\n",
      "Epoch 31: categorical_accuracy improved from 0.74090 to 0.74842, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 105s 293ms/step - loss: 0.5180 - categorical_accuracy: 0.7484 - val_loss: 0.4935 - val_categorical_accuracy: 0.7948 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5065 - categorical_accuracy: 0.7461\n",
      "Epoch 32: categorical_accuracy did not improve from 0.74842\n",
      "357/357 [==============================] - 99s 278ms/step - loss: 0.5065 - categorical_accuracy: 0.7461 - val_loss: 0.5522 - val_categorical_accuracy: 0.7701 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5360 - categorical_accuracy: 0.7521\n",
      "Epoch 33: categorical_accuracy improved from 0.74842 to 0.75210, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 109s 305ms/step - loss: 0.5360 - categorical_accuracy: 0.7521 - val_loss: 0.5436 - val_categorical_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5116 - categorical_accuracy: 0.7558\n",
      "Epoch 34: categorical_accuracy improved from 0.75210 to 0.75578, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 139s 390ms/step - loss: 0.5116 - categorical_accuracy: 0.7558 - val_loss: 0.4980 - val_categorical_accuracy: 0.7986 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5283 - categorical_accuracy: 0.7507\n",
      "Epoch 35: categorical_accuracy did not improve from 0.75578\n",
      "357/357 [==============================] - 122s 340ms/step - loss: 0.5283 - categorical_accuracy: 0.7507 - val_loss: 0.5326 - val_categorical_accuracy: 0.7785 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5166 - categorical_accuracy: 0.7621\n",
      "Epoch 36: categorical_accuracy improved from 0.75578 to 0.76208, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 126s 353ms/step - loss: 0.5166 - categorical_accuracy: 0.7621 - val_loss: 0.7002 - val_categorical_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.5144 - categorical_accuracy: 0.7908\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 37: categorical_accuracy improved from 0.76208 to 0.79079, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 123s 344ms/step - loss: 0.5144 - categorical_accuracy: 0.7908 - val_loss: 0.6710 - val_categorical_accuracy: 0.7384 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.4682 - categorical_accuracy: 0.8186\n",
      "Epoch 38: categorical_accuracy improved from 0.79079 to 0.81863, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 132s 370ms/step - loss: 0.4682 - categorical_accuracy: 0.8186 - val_loss: 0.4255 - val_categorical_accuracy: 0.8241 - lr: 2.0000e-04\n",
      "Epoch 39/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.4502 - categorical_accuracy: 0.8319\n",
      "Epoch 39: categorical_accuracy improved from 0.81863 to 0.83193, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 136s 382ms/step - loss: 0.4502 - categorical_accuracy: 0.8319 - val_loss: 0.3865 - val_categorical_accuracy: 0.8511 - lr: 2.0000e-04\n",
      "Epoch 40/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.4195 - categorical_accuracy: 0.8430\n",
      "Epoch 40: categorical_accuracy improved from 0.83193 to 0.84296, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 132s 369ms/step - loss: 0.4195 - categorical_accuracy: 0.8430 - val_loss: 0.4195 - val_categorical_accuracy: 0.8457 - lr: 2.0000e-04\n",
      "Epoch 41/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3995 - categorical_accuracy: 0.8547\n",
      "Epoch 41: categorical_accuracy improved from 0.84296 to 0.85469, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 136s 381ms/step - loss: 0.3995 - categorical_accuracy: 0.8547 - val_loss: 0.3712 - val_categorical_accuracy: 0.8472 - lr: 2.0000e-04\n",
      "Epoch 42/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3985 - categorical_accuracy: 0.8526\n",
      "Epoch 42: categorical_accuracy did not improve from 0.85469\n",
      "357/357 [==============================] - 163s 456ms/step - loss: 0.3985 - categorical_accuracy: 0.8526 - val_loss: 0.4093 - val_categorical_accuracy: 0.8326 - lr: 2.0000e-04\n",
      "Epoch 43/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3711 - categorical_accuracy: 0.8631\n",
      "Epoch 43: categorical_accuracy improved from 0.85469 to 0.86310, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 129s 360ms/step - loss: 0.3711 - categorical_accuracy: 0.8631 - val_loss: 0.3562 - val_categorical_accuracy: 0.8596 - lr: 2.0000e-04\n",
      "Epoch 44/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3915 - categorical_accuracy: 0.8510\n",
      "Epoch 44: categorical_accuracy did not improve from 0.86310\n",
      "357/357 [==============================] - 125s 349ms/step - loss: 0.3915 - categorical_accuracy: 0.8510 - val_loss: 0.3561 - val_categorical_accuracy: 0.8542 - lr: 2.0000e-04\n",
      "Epoch 45/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3927 - categorical_accuracy: 0.8496\n",
      "Epoch 45: categorical_accuracy did not improve from 0.86310\n",
      "357/357 [==============================] - 153s 429ms/step - loss: 0.3927 - categorical_accuracy: 0.8496 - val_loss: 0.3396 - val_categorical_accuracy: 0.8627 - lr: 2.0000e-04\n",
      "Epoch 46/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3844 - categorical_accuracy: 0.8566\n",
      "Epoch 46: categorical_accuracy did not improve from 0.86310\n",
      "357/357 [==============================] - 126s 353ms/step - loss: 0.3844 - categorical_accuracy: 0.8566 - val_loss: 0.3606 - val_categorical_accuracy: 0.8403 - lr: 2.0000e-04\n",
      "Epoch 47/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3649 - categorical_accuracy: 0.8657\n",
      "Epoch 47: categorical_accuracy improved from 0.86310 to 0.86572, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 137s 385ms/step - loss: 0.3649 - categorical_accuracy: 0.8657 - val_loss: 0.3446 - val_categorical_accuracy: 0.8642 - lr: 2.0000e-04\n",
      "Epoch 48/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3680 - categorical_accuracy: 0.8650\n",
      "Epoch 48: categorical_accuracy did not improve from 0.86572\n",
      "357/357 [==============================] - 117s 328ms/step - loss: 0.3680 - categorical_accuracy: 0.8650 - val_loss: 0.4014 - val_categorical_accuracy: 0.8225 - lr: 2.0000e-04\n",
      "Epoch 49/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3742 - categorical_accuracy: 0.8661\n",
      "Epoch 49: categorical_accuracy improved from 0.86572 to 0.86607, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 130s 363ms/step - loss: 0.3742 - categorical_accuracy: 0.8661 - val_loss: 0.3354 - val_categorical_accuracy: 0.8611 - lr: 2.0000e-04\n",
      "Epoch 50/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3655 - categorical_accuracy: 0.8662\n",
      "Epoch 50: categorical_accuracy improved from 0.86607 to 0.86625, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 130s 364ms/step - loss: 0.3655 - categorical_accuracy: 0.8662 - val_loss: 0.3626 - val_categorical_accuracy: 0.8488 - lr: 2.0000e-04\n",
      "Epoch 51/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3560 - categorical_accuracy: 0.8745\n",
      "Epoch 51: categorical_accuracy improved from 0.86625 to 0.87447, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 137s 383ms/step - loss: 0.3560 - categorical_accuracy: 0.8745 - val_loss: 0.3130 - val_categorical_accuracy: 0.8781 - lr: 2.0000e-04\n",
      "Epoch 52/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3524 - categorical_accuracy: 0.8722\n",
      "Epoch 52: categorical_accuracy did not improve from 0.87447\n",
      "357/357 [==============================] - 132s 370ms/step - loss: 0.3524 - categorical_accuracy: 0.8722 - val_loss: 0.4088 - val_categorical_accuracy: 0.8287 - lr: 2.0000e-04\n",
      "Epoch 53/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3444 - categorical_accuracy: 0.8764\n",
      "Epoch 53: categorical_accuracy improved from 0.87447 to 0.87640, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 136s 381ms/step - loss: 0.3444 - categorical_accuracy: 0.8764 - val_loss: 0.3153 - val_categorical_accuracy: 0.8735 - lr: 2.0000e-04\n",
      "Epoch 54/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3371 - categorical_accuracy: 0.8818\n",
      "Epoch 54: categorical_accuracy improved from 0.87640 to 0.88183, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 136s 380ms/step - loss: 0.3371 - categorical_accuracy: 0.8818 - val_loss: 0.3113 - val_categorical_accuracy: 0.8812 - lr: 2.0000e-04\n",
      "Epoch 55/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3345 - categorical_accuracy: 0.8834\n",
      "Epoch 55: categorical_accuracy improved from 0.88183 to 0.88340, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 137s 385ms/step - loss: 0.3345 - categorical_accuracy: 0.8834 - val_loss: 0.3932 - val_categorical_accuracy: 0.8241 - lr: 2.0000e-04\n",
      "Epoch 56/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3307 - categorical_accuracy: 0.8808\n",
      "Epoch 56: categorical_accuracy did not improve from 0.88340\n",
      "357/357 [==============================] - 100s 280ms/step - loss: 0.3307 - categorical_accuracy: 0.8808 - val_loss: 0.2935 - val_categorical_accuracy: 0.8827 - lr: 2.0000e-04\n",
      "Epoch 57/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3231 - categorical_accuracy: 0.8867\n",
      "Epoch 57: categorical_accuracy improved from 0.88340 to 0.88673, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 97s 270ms/step - loss: 0.3231 - categorical_accuracy: 0.8867 - val_loss: 0.2928 - val_categorical_accuracy: 0.8843 - lr: 2.0000e-04\n",
      "Epoch 58/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3329 - categorical_accuracy: 0.8820\n",
      "Epoch 58: categorical_accuracy did not improve from 0.88673\n",
      "357/357 [==============================] - 92s 258ms/step - loss: 0.3329 - categorical_accuracy: 0.8820 - val_loss: 0.3003 - val_categorical_accuracy: 0.8673 - lr: 2.0000e-04\n",
      "Epoch 59/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3272 - categorical_accuracy: 0.8834\n",
      "Epoch 59: categorical_accuracy did not improve from 0.88673\n",
      "357/357 [==============================] - 91s 256ms/step - loss: 0.3272 - categorical_accuracy: 0.8834 - val_loss: 0.3360 - val_categorical_accuracy: 0.8549 - lr: 2.0000e-04\n",
      "Epoch 60/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3217 - categorical_accuracy: 0.8860\n",
      "Epoch 60: categorical_accuracy did not improve from 0.88673\n",
      "357/357 [==============================] - 91s 255ms/step - loss: 0.3217 - categorical_accuracy: 0.8860 - val_loss: 0.3217 - val_categorical_accuracy: 0.8573 - lr: 2.0000e-04\n",
      "Epoch 61/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3005 - categorical_accuracy: 0.8976\n",
      "Epoch 61: categorical_accuracy improved from 0.88673 to 0.89758, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 97s 271ms/step - loss: 0.3005 - categorical_accuracy: 0.8976 - val_loss: 0.2646 - val_categorical_accuracy: 0.8958 - lr: 2.0000e-04\n",
      "Epoch 62/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.3115 - categorical_accuracy: 0.8913\n",
      "Epoch 62: categorical_accuracy did not improve from 0.89758\n",
      "357/357 [==============================] - 92s 257ms/step - loss: 0.3115 - categorical_accuracy: 0.8913 - val_loss: 0.3261 - val_categorical_accuracy: 0.8511 - lr: 2.0000e-04\n",
      "Epoch 63/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2873 - categorical_accuracy: 0.9007\n",
      "Epoch 63: categorical_accuracy improved from 0.89758 to 0.90074, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 98s 274ms/step - loss: 0.2873 - categorical_accuracy: 0.9007 - val_loss: 0.4156 - val_categorical_accuracy: 0.8125 - lr: 2.0000e-04\n",
      "Epoch 64/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2987 - categorical_accuracy: 0.8937\n",
      "Epoch 64: categorical_accuracy did not improve from 0.90074\n",
      "357/357 [==============================] - 94s 261ms/step - loss: 0.2987 - categorical_accuracy: 0.8937 - val_loss: 0.2937 - val_categorical_accuracy: 0.8727 - lr: 2.0000e-04\n",
      "Epoch 65/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2918 - categorical_accuracy: 0.9002\n",
      "Epoch 65: categorical_accuracy did not improve from 0.90074\n",
      "357/357 [==============================] - 92s 257ms/step - loss: 0.2918 - categorical_accuracy: 0.9002 - val_loss: 0.3087 - val_categorical_accuracy: 0.8735 - lr: 2.0000e-04\n",
      "Epoch 66/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2924 - categorical_accuracy: 0.8971\n",
      "Epoch 66: categorical_accuracy did not improve from 0.90074\n",
      "357/357 [==============================] - 101s 282ms/step - loss: 0.2924 - categorical_accuracy: 0.8971 - val_loss: 0.2608 - val_categorical_accuracy: 0.8904 - lr: 2.0000e-04\n",
      "Epoch 67/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2757 - categorical_accuracy: 0.9051\n",
      "Epoch 67: categorical_accuracy improved from 0.90074 to 0.90511, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 104s 290ms/step - loss: 0.2757 - categorical_accuracy: 0.9051 - val_loss: 0.3309 - val_categorical_accuracy: 0.8673 - lr: 2.0000e-04\n",
      "Epoch 68/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2992 - categorical_accuracy: 0.8964\n",
      "Epoch 68: categorical_accuracy did not improve from 0.90511\n",
      "357/357 [==============================] - 96s 269ms/step - loss: 0.2992 - categorical_accuracy: 0.8964 - val_loss: 0.2827 - val_categorical_accuracy: 0.8889 - lr: 2.0000e-04\n",
      "Epoch 69/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2810 - categorical_accuracy: 0.9013\n",
      "Epoch 69: categorical_accuracy did not improve from 0.90511\n",
      "357/357 [==============================] - 99s 276ms/step - loss: 0.2810 - categorical_accuracy: 0.9013 - val_loss: 0.3127 - val_categorical_accuracy: 0.8750 - lr: 2.0000e-04\n",
      "Epoch 70/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2797 - categorical_accuracy: 0.9025\n",
      "Epoch 70: categorical_accuracy did not improve from 0.90511\n",
      "357/357 [==============================] - 97s 271ms/step - loss: 0.2797 - categorical_accuracy: 0.9025 - val_loss: 0.2950 - val_categorical_accuracy: 0.8773 - lr: 2.0000e-04\n",
      "Epoch 71/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2753 - categorical_accuracy: 0.9048\n",
      "Epoch 71: categorical_accuracy did not improve from 0.90511\n",
      "357/357 [==============================] - 95s 267ms/step - loss: 0.2753 - categorical_accuracy: 0.9048 - val_loss: 0.3601 - val_categorical_accuracy: 0.8302 - lr: 2.0000e-04\n",
      "Epoch 72/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2582 - categorical_accuracy: 0.9095\n",
      "Epoch 72: categorical_accuracy improved from 0.90511 to 0.90949, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 102s 284ms/step - loss: 0.2582 - categorical_accuracy: 0.9095 - val_loss: 0.2594 - val_categorical_accuracy: 0.8912 - lr: 2.0000e-04\n",
      "Epoch 73/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2603 - categorical_accuracy: 0.9062\n",
      "Epoch 73: categorical_accuracy did not improve from 0.90949\n",
      "357/357 [==============================] - 96s 269ms/step - loss: 0.2603 - categorical_accuracy: 0.9062 - val_loss: 0.2810 - val_categorical_accuracy: 0.8835 - lr: 2.0000e-04\n",
      "Epoch 74/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2539 - categorical_accuracy: 0.9114\n",
      "Epoch 74: categorical_accuracy improved from 0.90949 to 0.91141, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 101s 283ms/step - loss: 0.2539 - categorical_accuracy: 0.9114 - val_loss: 0.3038 - val_categorical_accuracy: 0.8696 - lr: 2.0000e-04\n",
      "Epoch 75/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2746 - categorical_accuracy: 0.9086\n",
      "Epoch 75: categorical_accuracy did not improve from 0.91141\n",
      "357/357 [==============================] - 890s 2s/step - loss: 0.2746 - categorical_accuracy: 0.9086 - val_loss: 0.3054 - val_categorical_accuracy: 0.8588 - lr: 2.0000e-04\n",
      "Epoch 76/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2727 - categorical_accuracy: 0.9048\n",
      "Epoch 76: categorical_accuracy did not improve from 0.91141\n",
      "357/357 [==============================] - 98s 276ms/step - loss: 0.2727 - categorical_accuracy: 0.9048 - val_loss: 0.2630 - val_categorical_accuracy: 0.8981 - lr: 2.0000e-04\n",
      "Epoch 77/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2528 - categorical_accuracy: 0.9139\n",
      "Epoch 77: categorical_accuracy improved from 0.91141 to 0.91387, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 113s 317ms/step - loss: 0.2528 - categorical_accuracy: 0.9139 - val_loss: 0.3185 - val_categorical_accuracy: 0.8719 - lr: 2.0000e-04\n",
      "Epoch 78/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2572 - categorical_accuracy: 0.9053\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 78: categorical_accuracy did not improve from 0.91387\n",
      "357/357 [==============================] - 98s 273ms/step - loss: 0.2572 - categorical_accuracy: 0.9053 - val_loss: 0.2859 - val_categorical_accuracy: 0.8765 - lr: 2.0000e-04\n",
      "Epoch 79/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2560 - categorical_accuracy: 0.9056\n",
      "Epoch 79: categorical_accuracy did not improve from 0.91387\n",
      "357/357 [==============================] - 99s 277ms/step - loss: 0.2560 - categorical_accuracy: 0.9056 - val_loss: 0.2299 - val_categorical_accuracy: 0.9074 - lr: 4.0000e-05\n",
      "Epoch 80/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2665 - categorical_accuracy: 0.9063\n",
      "Epoch 80: categorical_accuracy did not improve from 0.91387\n",
      "357/357 [==============================] - 99s 278ms/step - loss: 0.2665 - categorical_accuracy: 0.9063 - val_loss: 0.2467 - val_categorical_accuracy: 0.8966 - lr: 4.0000e-05\n",
      "Epoch 81/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2623 - categorical_accuracy: 0.9053\n",
      "Epoch 81: categorical_accuracy did not improve from 0.91387\n",
      "357/357 [==============================] - 96s 270ms/step - loss: 0.2623 - categorical_accuracy: 0.9053 - val_loss: 0.2352 - val_categorical_accuracy: 0.8997 - lr: 4.0000e-05\n",
      "Epoch 82/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2433 - categorical_accuracy: 0.9161\n",
      "Epoch 82: categorical_accuracy improved from 0.91387 to 0.91614, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 109s 304ms/step - loss: 0.2433 - categorical_accuracy: 0.9161 - val_loss: 0.2466 - val_categorical_accuracy: 0.8974 - lr: 4.0000e-05\n",
      "Epoch 83/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2593 - categorical_accuracy: 0.9093\n",
      "Epoch 83: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 105s 294ms/step - loss: 0.2593 - categorical_accuracy: 0.9093 - val_loss: 0.2456 - val_categorical_accuracy: 0.8974 - lr: 4.0000e-05\n",
      "Epoch 84/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2615 - categorical_accuracy: 0.9100\n",
      "Epoch 84: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 114s 320ms/step - loss: 0.2615 - categorical_accuracy: 0.9100 - val_loss: 0.2510 - val_categorical_accuracy: 0.8951 - lr: 4.0000e-05\n",
      "Epoch 85/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2484 - categorical_accuracy: 0.9140\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 85: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 98s 273ms/step - loss: 0.2484 - categorical_accuracy: 0.9140 - val_loss: 0.2479 - val_categorical_accuracy: 0.9043 - lr: 4.0000e-05\n",
      "Epoch 86/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2652 - categorical_accuracy: 0.9109\n",
      "Epoch 86: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 98s 273ms/step - loss: 0.2652 - categorical_accuracy: 0.9109 - val_loss: 0.2461 - val_categorical_accuracy: 0.8974 - lr: 8.0000e-06\n",
      "Epoch 87/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2516 - categorical_accuracy: 0.9111\n",
      "Epoch 87: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 106s 296ms/step - loss: 0.2516 - categorical_accuracy: 0.9111 - val_loss: 0.2281 - val_categorical_accuracy: 0.9066 - lr: 8.0000e-06\n",
      "Epoch 88/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2435 - categorical_accuracy: 0.9135\n",
      "Epoch 88: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 100s 279ms/step - loss: 0.2435 - categorical_accuracy: 0.9135 - val_loss: 0.2442 - val_categorical_accuracy: 0.8958 - lr: 8.0000e-06\n",
      "Epoch 89/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2377 - categorical_accuracy: 0.9153\n",
      "Epoch 89: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 103s 289ms/step - loss: 0.2377 - categorical_accuracy: 0.9153 - val_loss: 0.2395 - val_categorical_accuracy: 0.8927 - lr: 8.0000e-06\n",
      "Epoch 90/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2385 - categorical_accuracy: 0.9147\n",
      "Epoch 90: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 103s 289ms/step - loss: 0.2385 - categorical_accuracy: 0.9147 - val_loss: 0.2386 - val_categorical_accuracy: 0.8935 - lr: 8.0000e-06\n",
      "Epoch 91/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2508 - categorical_accuracy: 0.9084\n",
      "Epoch 91: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 96s 268ms/step - loss: 0.2508 - categorical_accuracy: 0.9084 - val_loss: 0.2504 - val_categorical_accuracy: 0.8943 - lr: 8.0000e-06\n",
      "Epoch 92/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2432 - categorical_accuracy: 0.9133\n",
      "Epoch 92: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 94s 263ms/step - loss: 0.2432 - categorical_accuracy: 0.9133 - val_loss: 0.2336 - val_categorical_accuracy: 0.9028 - lr: 8.0000e-06\n",
      "Epoch 93/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2471 - categorical_accuracy: 0.9132\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 93: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 94s 264ms/step - loss: 0.2471 - categorical_accuracy: 0.9132 - val_loss: 0.2478 - val_categorical_accuracy: 0.8981 - lr: 8.0000e-06\n",
      "Epoch 94/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2543 - categorical_accuracy: 0.9109\n",
      "Epoch 94: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 95s 266ms/step - loss: 0.2543 - categorical_accuracy: 0.9109 - val_loss: 0.2320 - val_categorical_accuracy: 0.9074 - lr: 1.6000e-06\n",
      "Epoch 95/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2395 - categorical_accuracy: 0.9133\n",
      "Epoch 95: categorical_accuracy did not improve from 0.91614\n",
      "357/357 [==============================] - 96s 269ms/step - loss: 0.2395 - categorical_accuracy: 0.9133 - val_loss: 0.2370 - val_categorical_accuracy: 0.8958 - lr: 1.6000e-06\n",
      "Epoch 96/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2260 - categorical_accuracy: 0.9207\n",
      "Epoch 96: categorical_accuracy improved from 0.91614 to 0.92069, saving model to temp\\model1_weights.h5\n",
      "357/357 [==============================] - 101s 282ms/step - loss: 0.2260 - categorical_accuracy: 0.9207 - val_loss: 0.2266 - val_categorical_accuracy: 0.9020 - lr: 1.6000e-06\n",
      "Epoch 97/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2310 - categorical_accuracy: 0.9167\n",
      "Epoch 97: categorical_accuracy did not improve from 0.92069\n",
      "357/357 [==============================] - 95s 265ms/step - loss: 0.2310 - categorical_accuracy: 0.9167 - val_loss: 0.2327 - val_categorical_accuracy: 0.8997 - lr: 1.6000e-06\n",
      "Epoch 98/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2382 - categorical_accuracy: 0.9186\n",
      "Epoch 98: categorical_accuracy did not improve from 0.92069\n",
      "357/357 [==============================] - 94s 263ms/step - loss: 0.2382 - categorical_accuracy: 0.9186 - val_loss: 0.2325 - val_categorical_accuracy: 0.9005 - lr: 1.6000e-06\n",
      "Epoch 99/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2545 - categorical_accuracy: 0.9086\n",
      "Epoch 99: categorical_accuracy did not improve from 0.92069\n",
      "357/357 [==============================] - 94s 263ms/step - loss: 0.2545 - categorical_accuracy: 0.9086 - val_loss: 0.2348 - val_categorical_accuracy: 0.9059 - lr: 1.6000e-06\n",
      "Epoch 100/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2417 - categorical_accuracy: 0.9165\n",
      "Epoch 100: categorical_accuracy did not improve from 0.92069\n",
      "357/357 [==============================] - 95s 266ms/step - loss: 0.2417 - categorical_accuracy: 0.9165 - val_loss: 0.2310 - val_categorical_accuracy: 0.9012 - lr: 1.6000e-06\n",
      "Epoch 101/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2390 - categorical_accuracy: 0.9158\n",
      "Epoch 101: categorical_accuracy did not improve from 0.92069\n",
      "357/357 [==============================] - 94s 263ms/step - loss: 0.2390 - categorical_accuracy: 0.9158 - val_loss: 0.2359 - val_categorical_accuracy: 0.9028 - lr: 1.6000e-06\n",
      "Epoch 102/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2365 - categorical_accuracy: 0.9158\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 102: categorical_accuracy did not improve from 0.92069\n",
      "357/357 [==============================] - 94s 264ms/step - loss: 0.2365 - categorical_accuracy: 0.9158 - val_loss: 0.2558 - val_categorical_accuracy: 0.8904 - lr: 1.6000e-06\n",
      "Epoch 103/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2436 - categorical_accuracy: 0.9149\n",
      "Epoch 103: categorical_accuracy did not improve from 0.92069\n",
      "357/357 [==============================] - 95s 265ms/step - loss: 0.2436 - categorical_accuracy: 0.9149 - val_loss: 0.2438 - val_categorical_accuracy: 0.8958 - lr: 3.2000e-07\n",
      "Epoch 104/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2401 - categorical_accuracy: 0.9160\n",
      "Epoch 104: categorical_accuracy did not improve from 0.92069\n",
      "357/357 [==============================] - 94s 264ms/step - loss: 0.2401 - categorical_accuracy: 0.9160 - val_loss: 0.2416 - val_categorical_accuracy: 0.8974 - lr: 3.2000e-07\n",
      "Epoch 105/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2440 - categorical_accuracy: 0.9153\n",
      "Epoch 105: categorical_accuracy did not improve from 0.92069\n",
      "357/357 [==============================] - 94s 263ms/step - loss: 0.2440 - categorical_accuracy: 0.9153 - val_loss: 0.2503 - val_categorical_accuracy: 0.9012 - lr: 3.2000e-07\n",
      "Epoch 106/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2428 - categorical_accuracy: 0.9135\n",
      "Epoch 106: categorical_accuracy did not improve from 0.92069\n",
      "357/357 [==============================] - 95s 266ms/step - loss: 0.2428 - categorical_accuracy: 0.9135 - val_loss: 0.2372 - val_categorical_accuracy: 0.8904 - lr: 3.2000e-07\n",
      "Epoch 107/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2489 - categorical_accuracy: 0.9156\n",
      "Epoch 107: categorical_accuracy did not improve from 0.92069\n",
      "357/357 [==============================] - 93s 261ms/step - loss: 0.2489 - categorical_accuracy: 0.9156 - val_loss: 0.2384 - val_categorical_accuracy: 0.8958 - lr: 3.2000e-07\n",
      "Epoch 108/120\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.2388 - categorical_accuracy: 0.9146\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 108: categorical_accuracy did not improve from 0.92069\n",
      "357/357 [==============================] - 93s 261ms/step - loss: 0.2388 - categorical_accuracy: 0.9146 - val_loss: 0.2337 - val_categorical_accuracy: 0.8951 - lr: 3.2000e-07\n",
      "Epoch 108: early stopping\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "# Convolutional layer 1\n",
    "model1.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape=(224, 224, 3), activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides = 2))\n",
    "\n",
    "# Convolutional layer 2\n",
    "model1.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Convolutional layer 3\n",
    "model1.add(Conv2D(128,(3,3), activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "# Feedforward\n",
    "model1.add(Dense(units= 512, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(units=512, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.0001, clipvalue=0.5)\n",
    "model1.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                   metrics= ['categorical_accuracy'])\n",
    "\n",
    "model1_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model1_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "model1_mcp = ModelCheckpoint(filepath = r'temp\\model1_weights.h5', monitor = 'categorical_accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n",
    "history1 = model1.fit(train, steps_per_epoch=5712//16, epochs=120, validation_data=test, validation_steps= 1311//16, callbacks=[model1_es, model1_rlr, model1_mcp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('models/self_3conv_2ff.h5') is False:\n",
    "    model1.save('models/self_3conv_2ff.h5')\n",
    "    \n",
    "self_3conv_2ff = load_model('models/self_3conv_2ff.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - VGG16 (No Convolution Trained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 3s 0us/step\n",
      "Epoch 1/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.5659 - categorical_accuracy: 0.7303\n",
      "Epoch 1: categorical_accuracy improved from -inf to 0.73034, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 64s 352ms/step - loss: 1.5659 - categorical_accuracy: 0.7303 - val_loss: 0.5245 - val_categorical_accuracy: 0.8047 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3875 - categorical_accuracy: 0.8536\n",
      "Epoch 2: categorical_accuracy improved from 0.73034 to 0.85358, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 69s 389ms/step - loss: 0.3875 - categorical_accuracy: 0.8536 - val_loss: 0.6314 - val_categorical_accuracy: 0.7531 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3343 - categorical_accuracy: 0.8764\n",
      "Epoch 3: categorical_accuracy improved from 0.85358 to 0.87640, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 66s 372ms/step - loss: 0.3343 - categorical_accuracy: 0.8764 - val_loss: 0.3859 - val_categorical_accuracy: 0.8578 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3476 - categorical_accuracy: 0.8732\n",
      "Epoch 4: categorical_accuracy did not improve from 0.87640\n",
      "178/178 [==============================] - 55s 309ms/step - loss: 0.3476 - categorical_accuracy: 0.8732 - val_loss: 0.4774 - val_categorical_accuracy: 0.8469 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2863 - categorical_accuracy: 0.8947\n",
      "Epoch 5: categorical_accuracy improved from 0.87640 to 0.89466, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 72s 404ms/step - loss: 0.2863 - categorical_accuracy: 0.8947 - val_loss: 0.4200 - val_categorical_accuracy: 0.8562 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2709 - categorical_accuracy: 0.9031\n",
      "Epoch 6: categorical_accuracy improved from 0.89466 to 0.90309, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 70s 394ms/step - loss: 0.2709 - categorical_accuracy: 0.9031 - val_loss: 0.3345 - val_categorical_accuracy: 0.8703 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2164 - categorical_accuracy: 0.9263\n",
      "Epoch 7: categorical_accuracy improved from 0.90309 to 0.92626, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 67s 373ms/step - loss: 0.2164 - categorical_accuracy: 0.9263 - val_loss: 0.2899 - val_categorical_accuracy: 0.8813 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2152 - categorical_accuracy: 0.9235\n",
      "Epoch 8: categorical_accuracy did not improve from 0.92626\n",
      "178/178 [==============================] - 55s 310ms/step - loss: 0.2152 - categorical_accuracy: 0.9235 - val_loss: 0.2546 - val_categorical_accuracy: 0.8969 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2061 - categorical_accuracy: 0.9235\n",
      "Epoch 9: categorical_accuracy did not improve from 0.92626\n",
      "178/178 [==============================] - 55s 310ms/step - loss: 0.2061 - categorical_accuracy: 0.9235 - val_loss: 0.3279 - val_categorical_accuracy: 0.8562 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1862 - categorical_accuracy: 0.9329\n",
      "Epoch 10: categorical_accuracy improved from 0.92626 to 0.93294, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 68s 379ms/step - loss: 0.1862 - categorical_accuracy: 0.9329 - val_loss: 0.2349 - val_categorical_accuracy: 0.9016 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1569 - categorical_accuracy: 0.9421\n",
      "Epoch 11: categorical_accuracy improved from 0.93294 to 0.94206, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 66s 369ms/step - loss: 0.1569 - categorical_accuracy: 0.9421 - val_loss: 0.2950 - val_categorical_accuracy: 0.8797 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1573 - categorical_accuracy: 0.9393\n",
      "Epoch 12: categorical_accuracy did not improve from 0.94206\n",
      "178/178 [==============================] - 55s 309ms/step - loss: 0.1573 - categorical_accuracy: 0.9393 - val_loss: 0.2022 - val_categorical_accuracy: 0.9219 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1587 - categorical_accuracy: 0.9417\n",
      "Epoch 13: categorical_accuracy did not improve from 0.94206\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 0.1587 - categorical_accuracy: 0.9417 - val_loss: 0.2019 - val_categorical_accuracy: 0.9141 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1475 - categorical_accuracy: 0.9424\n",
      "Epoch 14: categorical_accuracy improved from 0.94206 to 0.94242, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 68s 384ms/step - loss: 0.1475 - categorical_accuracy: 0.9424 - val_loss: 0.2025 - val_categorical_accuracy: 0.9109 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1432 - categorical_accuracy: 0.9449\n",
      "Epoch 15: categorical_accuracy improved from 0.94242 to 0.94487, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 64s 361ms/step - loss: 0.1432 - categorical_accuracy: 0.9449 - val_loss: 0.1662 - val_categorical_accuracy: 0.9312 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1218 - categorical_accuracy: 0.9582\n",
      "Epoch 16: categorical_accuracy improved from 0.94487 to 0.95822, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 66s 370ms/step - loss: 0.1218 - categorical_accuracy: 0.9582 - val_loss: 0.4102 - val_categorical_accuracy: 0.8687 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1101 - categorical_accuracy: 0.9561\n",
      "Epoch 17: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 56s 310ms/step - loss: 0.1101 - categorical_accuracy: 0.9561 - val_loss: 0.1859 - val_categorical_accuracy: 0.9375 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1595 - categorical_accuracy: 0.9389\n",
      "Epoch 18: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 73s 407ms/step - loss: 0.1595 - categorical_accuracy: 0.9389 - val_loss: 0.3759 - val_categorical_accuracy: 0.8703 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1191 - categorical_accuracy: 0.9551\n",
      "Epoch 19: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 64s 357ms/step - loss: 0.1191 - categorical_accuracy: 0.9551 - val_loss: 0.2473 - val_categorical_accuracy: 0.9094 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0932 - categorical_accuracy: 0.9680\n",
      "Epoch 20: categorical_accuracy improved from 0.95822 to 0.96805, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 71s 401ms/step - loss: 0.0932 - categorical_accuracy: 0.9680 - val_loss: 0.2446 - val_categorical_accuracy: 0.9234 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0983 - categorical_accuracy: 0.9635\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 21: categorical_accuracy did not improve from 0.96805\n",
      "178/178 [==============================] - 59s 332ms/step - loss: 0.0983 - categorical_accuracy: 0.9635 - val_loss: 0.1937 - val_categorical_accuracy: 0.9375 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0569 - categorical_accuracy: 0.9803\n",
      "Epoch 22: categorical_accuracy improved from 0.96805 to 0.98034, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 70s 391ms/step - loss: 0.0569 - categorical_accuracy: 0.9803 - val_loss: 0.1431 - val_categorical_accuracy: 0.9406 - lr: 2.0000e-04\n",
      "Epoch 23/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0531 - categorical_accuracy: 0.9817\n",
      "Epoch 23: categorical_accuracy improved from 0.98034 to 0.98174, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 67s 376ms/step - loss: 0.0531 - categorical_accuracy: 0.9817 - val_loss: 0.1039 - val_categorical_accuracy: 0.9547 - lr: 2.0000e-04\n",
      "Epoch 24/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0457 - categorical_accuracy: 0.9842\n",
      "Epoch 24: categorical_accuracy improved from 0.98174 to 0.98420, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 66s 372ms/step - loss: 0.0457 - categorical_accuracy: 0.9842 - val_loss: 0.0714 - val_categorical_accuracy: 0.9797 - lr: 2.0000e-04\n",
      "Epoch 25/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0429 - categorical_accuracy: 0.9846\n",
      "Epoch 25: categorical_accuracy improved from 0.98420 to 0.98455, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 67s 375ms/step - loss: 0.0429 - categorical_accuracy: 0.9846 - val_loss: 0.1231 - val_categorical_accuracy: 0.9594 - lr: 2.0000e-04\n",
      "Epoch 26/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0422 - categorical_accuracy: 0.9867\n",
      "Epoch 26: categorical_accuracy improved from 0.98455 to 0.98666, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 68s 379ms/step - loss: 0.0422 - categorical_accuracy: 0.9867 - val_loss: 0.0895 - val_categorical_accuracy: 0.9672 - lr: 2.0000e-04\n",
      "Epoch 27/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0408 - categorical_accuracy: 0.9870\n",
      "Epoch 27: categorical_accuracy improved from 0.98666 to 0.98701, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 71s 396ms/step - loss: 0.0408 - categorical_accuracy: 0.9870 - val_loss: 0.1515 - val_categorical_accuracy: 0.9516 - lr: 2.0000e-04\n",
      "Epoch 28/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0391 - categorical_accuracy: 0.9870\n",
      "Epoch 28: categorical_accuracy did not improve from 0.98701\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 0.0391 - categorical_accuracy: 0.9870 - val_loss: 0.0855 - val_categorical_accuracy: 0.9703 - lr: 2.0000e-04\n",
      "Epoch 29/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0402 - categorical_accuracy: 0.9881\n",
      "Epoch 29: categorical_accuracy improved from 0.98701 to 0.98806, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 68s 383ms/step - loss: 0.0402 - categorical_accuracy: 0.9881 - val_loss: 0.0941 - val_categorical_accuracy: 0.9703 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0384 - categorical_accuracy: 0.9874\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 30: categorical_accuracy did not improve from 0.98806\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 0.0384 - categorical_accuracy: 0.9874 - val_loss: 0.0815 - val_categorical_accuracy: 0.9734 - lr: 2.0000e-04\n",
      "Epoch 31/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0321 - categorical_accuracy: 0.9905\n",
      "Epoch 31: categorical_accuracy improved from 0.98806 to 0.99052, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 67s 377ms/step - loss: 0.0321 - categorical_accuracy: 0.9905 - val_loss: 0.1010 - val_categorical_accuracy: 0.9641 - lr: 4.0000e-05\n",
      "Epoch 32/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0312 - categorical_accuracy: 0.9905\n",
      "Epoch 32: categorical_accuracy did not improve from 0.99052\n",
      "178/178 [==============================] - 56s 314ms/step - loss: 0.0312 - categorical_accuracy: 0.9905 - val_loss: 0.0986 - val_categorical_accuracy: 0.9641 - lr: 4.0000e-05\n",
      "Epoch 33/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0295 - categorical_accuracy: 0.9902\n",
      "Epoch 33: categorical_accuracy did not improve from 0.99052\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 0.0295 - categorical_accuracy: 0.9902 - val_loss: 0.1040 - val_categorical_accuracy: 0.9672 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0226 - categorical_accuracy: 0.9926\n",
      "Epoch 34: categorical_accuracy improved from 0.99052 to 0.99263, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 71s 397ms/step - loss: 0.0226 - categorical_accuracy: 0.9926 - val_loss: 0.1155 - val_categorical_accuracy: 0.9672 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0269 - categorical_accuracy: 0.9905\n",
      "Epoch 35: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 56s 311ms/step - loss: 0.0269 - categorical_accuracy: 0.9905 - val_loss: 0.1237 - val_categorical_accuracy: 0.9625 - lr: 4.0000e-05\n",
      "Epoch 36/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0304 - categorical_accuracy: 0.9895\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 36: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 56s 316ms/step - loss: 0.0304 - categorical_accuracy: 0.9895 - val_loss: 0.0996 - val_categorical_accuracy: 0.9672 - lr: 4.0000e-05\n",
      "Epoch 37/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0228 - categorical_accuracy: 0.9923\n",
      "Epoch 37: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 57s 320ms/step - loss: 0.0228 - categorical_accuracy: 0.9923 - val_loss: 0.1200 - val_categorical_accuracy: 0.9641 - lr: 8.0000e-06\n",
      "Epoch 38/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0258 - categorical_accuracy: 0.9919\n",
      "Epoch 38: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 57s 320ms/step - loss: 0.0258 - categorical_accuracy: 0.9919 - val_loss: 0.0853 - val_categorical_accuracy: 0.9672 - lr: 8.0000e-06\n",
      "Epoch 39/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0288 - categorical_accuracy: 0.9874\n",
      "Epoch 39: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 57s 320ms/step - loss: 0.0288 - categorical_accuracy: 0.9874 - val_loss: 0.0824 - val_categorical_accuracy: 0.9734 - lr: 8.0000e-06\n",
      "Epoch 40/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0243 - categorical_accuracy: 0.9923\n",
      "Epoch 40: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 58s 325ms/step - loss: 0.0243 - categorical_accuracy: 0.9923 - val_loss: 0.0599 - val_categorical_accuracy: 0.9766 - lr: 8.0000e-06\n",
      "Epoch 41/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0242 - categorical_accuracy: 0.9919\n",
      "Epoch 41: categorical_accuracy did not improve from 0.99263\n",
      "178/178 [==============================] - 57s 322ms/step - loss: 0.0242 - categorical_accuracy: 0.9919 - val_loss: 0.0929 - val_categorical_accuracy: 0.9781 - lr: 8.0000e-06\n",
      "Epoch 42/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0227 - categorical_accuracy: 0.9933\n",
      "Epoch 42: categorical_accuracy improved from 0.99263 to 0.99333, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 68s 381ms/step - loss: 0.0227 - categorical_accuracy: 0.9933 - val_loss: 0.0797 - val_categorical_accuracy: 0.9734 - lr: 8.0000e-06\n",
      "Epoch 43/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0210 - categorical_accuracy: 0.9951\n",
      "Epoch 43: categorical_accuracy improved from 0.99333 to 0.99508, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 66s 372ms/step - loss: 0.0210 - categorical_accuracy: 0.9951 - val_loss: 0.0952 - val_categorical_accuracy: 0.9641 - lr: 8.0000e-06\n",
      "Epoch 44/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0200 - categorical_accuracy: 0.9916\n",
      "Epoch 44: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 56s 312ms/step - loss: 0.0200 - categorical_accuracy: 0.9916 - val_loss: 0.0664 - val_categorical_accuracy: 0.9781 - lr: 8.0000e-06\n",
      "Epoch 45/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0301 - categorical_accuracy: 0.9919\n",
      "Epoch 45: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 0.0301 - categorical_accuracy: 0.9919 - val_loss: 0.1226 - val_categorical_accuracy: 0.9625 - lr: 8.0000e-06\n",
      "Epoch 46/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0271 - categorical_accuracy: 0.9919\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 46: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 0.0271 - categorical_accuracy: 0.9919 - val_loss: 0.0960 - val_categorical_accuracy: 0.9719 - lr: 8.0000e-06\n",
      "Epoch 47/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0298 - categorical_accuracy: 0.9912\n",
      "Epoch 47: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 0.0298 - categorical_accuracy: 0.9912 - val_loss: 0.0729 - val_categorical_accuracy: 0.9766 - lr: 1.6000e-06\n",
      "Epoch 48/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0237 - categorical_accuracy: 0.9940\n",
      "Epoch 48: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 321ms/step - loss: 0.0237 - categorical_accuracy: 0.9940 - val_loss: 0.0644 - val_categorical_accuracy: 0.9812 - lr: 1.6000e-06\n",
      "Epoch 49/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0218 - categorical_accuracy: 0.9933\n",
      "Epoch 49: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 320ms/step - loss: 0.0218 - categorical_accuracy: 0.9933 - val_loss: 0.1038 - val_categorical_accuracy: 0.9656 - lr: 1.6000e-06\n",
      "Epoch 50/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0245 - categorical_accuracy: 0.9919\n",
      "Epoch 50: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 0.0245 - categorical_accuracy: 0.9919 - val_loss: 0.0961 - val_categorical_accuracy: 0.9688 - lr: 1.6000e-06\n",
      "Epoch 51/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0242 - categorical_accuracy: 0.9919\n",
      "Epoch 51: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 321ms/step - loss: 0.0242 - categorical_accuracy: 0.9919 - val_loss: 0.0861 - val_categorical_accuracy: 0.9734 - lr: 1.6000e-06\n",
      "Epoch 52/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0227 - categorical_accuracy: 0.9933\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 52: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 0.0227 - categorical_accuracy: 0.9933 - val_loss: 0.0669 - val_categorical_accuracy: 0.9797 - lr: 1.6000e-06\n",
      "Epoch 53/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0224 - categorical_accuracy: 0.9930\n",
      "Epoch 53: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 0.0224 - categorical_accuracy: 0.9930 - val_loss: 0.0971 - val_categorical_accuracy: 0.9719 - lr: 3.2000e-07\n",
      "Epoch 54/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0205 - categorical_accuracy: 0.9937\n",
      "Epoch 54: categorical_accuracy did not improve from 0.99508\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 0.0205 - categorical_accuracy: 0.9937 - val_loss: 0.0912 - val_categorical_accuracy: 0.9719 - lr: 3.2000e-07\n",
      "Epoch 55/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0150 - categorical_accuracy: 0.9968\n",
      "Epoch 55: categorical_accuracy improved from 0.99508 to 0.99684, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 132s 741ms/step - loss: 0.0150 - categorical_accuracy: 0.9968 - val_loss: 0.0885 - val_categorical_accuracy: 0.9734 - lr: 3.2000e-07\n",
      "Epoch 56/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0222 - categorical_accuracy: 0.9909\n",
      "Epoch 56: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 152s 851ms/step - loss: 0.0222 - categorical_accuracy: 0.9909 - val_loss: 0.0935 - val_categorical_accuracy: 0.9766 - lr: 3.2000e-07\n",
      "Epoch 57/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0230 - categorical_accuracy: 0.9933\n",
      "Epoch 57: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 105s 588ms/step - loss: 0.0230 - categorical_accuracy: 0.9933 - val_loss: 0.0745 - val_categorical_accuracy: 0.9766 - lr: 3.2000e-07\n",
      "Epoch 58/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0227 - categorical_accuracy: 0.9923\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 58: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 54s 303ms/step - loss: 0.0227 - categorical_accuracy: 0.9923 - val_loss: 0.0986 - val_categorical_accuracy: 0.9672 - lr: 3.2000e-07\n",
      "Epoch 59/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0202 - categorical_accuracy: 0.9951\n",
      "Epoch 59: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 73s 410ms/step - loss: 0.0202 - categorical_accuracy: 0.9951 - val_loss: 0.0895 - val_categorical_accuracy: 0.9641 - lr: 6.4000e-08\n",
      "Epoch 60/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0210 - categorical_accuracy: 0.9937\n",
      "Epoch 60: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 66s 371ms/step - loss: 0.0210 - categorical_accuracy: 0.9937 - val_loss: 0.0870 - val_categorical_accuracy: 0.9703 - lr: 6.4000e-08\n",
      "Epoch 61/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0222 - categorical_accuracy: 0.9930\n",
      "Epoch 61: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 64s 360ms/step - loss: 0.0222 - categorical_accuracy: 0.9930 - val_loss: 0.0833 - val_categorical_accuracy: 0.9703 - lr: 6.4000e-08\n",
      "Epoch 62/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0218 - categorical_accuracy: 0.9916\n",
      "Epoch 62: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 55s 308ms/step - loss: 0.0218 - categorical_accuracy: 0.9916 - val_loss: 0.1021 - val_categorical_accuracy: 0.9703 - lr: 6.4000e-08\n",
      "Epoch 63/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0188 - categorical_accuracy: 0.9944\n",
      "Epoch 63: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 55s 306ms/step - loss: 0.0188 - categorical_accuracy: 0.9944 - val_loss: 0.0872 - val_categorical_accuracy: 0.9625 - lr: 6.4000e-08\n",
      "Epoch 64/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0263 - categorical_accuracy: 0.9912\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "\n",
      "Epoch 64: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 55s 310ms/step - loss: 0.0263 - categorical_accuracy: 0.9912 - val_loss: 0.0889 - val_categorical_accuracy: 0.9719 - lr: 6.4000e-08\n",
      "Epoch 65/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0230 - categorical_accuracy: 0.9916\n",
      "Epoch 65: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 55s 310ms/step - loss: 0.0230 - categorical_accuracy: 0.9916 - val_loss: 0.0836 - val_categorical_accuracy: 0.9734 - lr: 1.2800e-08\n",
      "Epoch 66/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0182 - categorical_accuracy: 0.9947\n",
      "Epoch 66: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 56s 312ms/step - loss: 0.0182 - categorical_accuracy: 0.9947 - val_loss: 0.0810 - val_categorical_accuracy: 0.9719 - lr: 1.2800e-08\n",
      "Epoch 67/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0274 - categorical_accuracy: 0.9930\n",
      "Epoch 67: categorical_accuracy did not improve from 0.99684\n",
      "178/178 [==============================] - 56s 313ms/step - loss: 0.0274 - categorical_accuracy: 0.9930 - val_loss: 0.0678 - val_categorical_accuracy: 0.9734 - lr: 1.2800e-08\n",
      "Epoch 67: early stopping\n"
     ]
    }
   ],
   "source": [
    "vgg16_conv = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg16_conv.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "vgg_feedforward = Flatten()(vgg16_conv.output)\n",
    "vgg_feedforward = Dense(4096,activation = 'relu')(vgg_feedforward)\n",
    "vgg_feedforward = Dense(1024,activation = 'relu')(vgg_feedforward)\n",
    "\n",
    "prediction = Dense(4, activation='softmax')(vgg_feedforward)\n",
    "\n",
    "model_vgg16 = Model(inputs=vgg16_conv.input, outputs=prediction)\n",
    "\n",
    "model_vgg16.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model1_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model1_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "\n",
    "# Automatically saves the best weights of the model, based on best val_accuracy\n",
    "model1_mcp = ModelCheckpoint(filepath = r'temp\\model1_weights.h5', monitor = 'categorical_accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n",
    "vgg16_fit = model_vgg16.fit(\n",
    "  train,\n",
    "  validation_data=test,\n",
    "  epochs=100,\n",
    "  steps_per_epoch=5712//32,\n",
    "  validation_steps=1311//32,\n",
    "  callbacks=[model1_es, model1_rlr, model1_mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 222, 222, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 109, 109, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 52, 52, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,661,700\n",
      "Trainable params: 44,661,252\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('models/vgg16_4096_1024.h5') is False:\n",
    "    model1.save('models/vgg16_4096_1024.h5')\n",
    "\n",
    "vgg16_4096_1024 = load_model('models/vgg16_4096_1024.h5')\n",
    "print(vgg16_4096_1024.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 - VGG16 (Last Convolution Trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.4071 - categorical_accuracy: 0.2637\n",
      "Epoch 1: categorical_accuracy improved from -inf to 0.26369, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 62s 339ms/step - loss: 1.4071 - categorical_accuracy: 0.2637 - val_loss: 1.3822 - val_categorical_accuracy: 0.3281 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3850 - categorical_accuracy: 0.2707\n",
      "Epoch 2: categorical_accuracy improved from 0.26369 to 0.27072, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 61s 340ms/step - loss: 1.3850 - categorical_accuracy: 0.2707 - val_loss: 1.3825 - val_categorical_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3831 - categorical_accuracy: 0.2820\n",
      "Epoch 3: categorical_accuracy improved from 0.27072 to 0.28195, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 60s 339ms/step - loss: 1.3831 - categorical_accuracy: 0.2820 - val_loss: 1.3858 - val_categorical_accuracy: 0.2937 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3847 - categorical_accuracy: 0.2742\n",
      "Epoch 4: categorical_accuracy did not improve from 0.28195\n",
      "178/178 [==============================] - 58s 325ms/step - loss: 1.3847 - categorical_accuracy: 0.2742 - val_loss: 1.3817 - val_categorical_accuracy: 0.3172 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3837 - categorical_accuracy: 0.2834\n",
      "Epoch 5: categorical_accuracy improved from 0.28195 to 0.28336, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 322ms/step - loss: 1.3837 - categorical_accuracy: 0.2834 - val_loss: 1.3801 - val_categorical_accuracy: 0.3063 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3838 - categorical_accuracy: 0.2770\n",
      "Epoch 6: categorical_accuracy did not improve from 0.28336\n",
      "178/178 [==============================] - 57s 321ms/step - loss: 1.3838 - categorical_accuracy: 0.2770 - val_loss: 1.3808 - val_categorical_accuracy: 0.3016 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3825 - categorical_accuracy: 0.2834\n",
      "Epoch 7: categorical_accuracy did not improve from 0.28336\n",
      "178/178 [==============================] - 60s 334ms/step - loss: 1.3825 - categorical_accuracy: 0.2834 - val_loss: 1.3857 - val_categorical_accuracy: 0.2828 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3844 - categorical_accuracy: 0.2725\n",
      "Epoch 8: categorical_accuracy did not improve from 0.28336\n",
      "178/178 [==============================] - 62s 346ms/step - loss: 1.3844 - categorical_accuracy: 0.2725 - val_loss: 1.3822 - val_categorical_accuracy: 0.2953 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3825 - categorical_accuracy: 0.2890\n",
      "Epoch 9: categorical_accuracy improved from 0.28336 to 0.28897, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 61s 345ms/step - loss: 1.3825 - categorical_accuracy: 0.2890 - val_loss: 1.3802 - val_categorical_accuracy: 0.3172 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3833 - categorical_accuracy: 0.2827\n",
      "Epoch 10: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 62s 347ms/step - loss: 1.3833 - categorical_accuracy: 0.2827 - val_loss: 1.3772 - val_categorical_accuracy: 0.3328 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3841 - categorical_accuracy: 0.2753\n",
      "Epoch 11: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 63s 354ms/step - loss: 1.3841 - categorical_accuracy: 0.2753 - val_loss: 1.3837 - val_categorical_accuracy: 0.2906 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3822 - categorical_accuracy: 0.2837\n",
      "Epoch 12: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 61s 344ms/step - loss: 1.3822 - categorical_accuracy: 0.2837 - val_loss: 1.3799 - val_categorical_accuracy: 0.3047 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3831 - categorical_accuracy: 0.2823\n",
      "Epoch 13: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 61s 344ms/step - loss: 1.3831 - categorical_accuracy: 0.2823 - val_loss: 1.3839 - val_categorical_accuracy: 0.3063 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3833 - categorical_accuracy: 0.2795\n",
      "Epoch 14: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 68s 381ms/step - loss: 1.3833 - categorical_accuracy: 0.2795 - val_loss: 1.3810 - val_categorical_accuracy: 0.3094 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3834 - categorical_accuracy: 0.2753\n",
      "Epoch 15: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 61s 341ms/step - loss: 1.3834 - categorical_accuracy: 0.2753 - val_loss: 1.3768 - val_categorical_accuracy: 0.3359 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3834 - categorical_accuracy: 0.2798\n",
      "Epoch 16: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 64s 357ms/step - loss: 1.3834 - categorical_accuracy: 0.2798 - val_loss: 1.3820 - val_categorical_accuracy: 0.2984 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3827 - categorical_accuracy: 0.2837\n",
      "Epoch 17: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 66s 368ms/step - loss: 1.3827 - categorical_accuracy: 0.2837 - val_loss: 1.3810 - val_categorical_accuracy: 0.2922 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3830 - categorical_accuracy: 0.2812\n",
      "Epoch 18: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 64s 357ms/step - loss: 1.3830 - categorical_accuracy: 0.2812 - val_loss: 1.3796 - val_categorical_accuracy: 0.3234 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3830 - categorical_accuracy: 0.2851\n",
      "Epoch 19: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 61s 342ms/step - loss: 1.3830 - categorical_accuracy: 0.2851 - val_loss: 1.3805 - val_categorical_accuracy: 0.3172 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3821 - categorical_accuracy: 0.2802\n",
      "Epoch 20: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 65s 363ms/step - loss: 1.3821 - categorical_accuracy: 0.2802 - val_loss: 1.3756 - val_categorical_accuracy: 0.3281 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3850 - categorical_accuracy: 0.2686\n",
      "Epoch 21: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 67s 378ms/step - loss: 1.3850 - categorical_accuracy: 0.2686 - val_loss: 1.3816 - val_categorical_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3827 - categorical_accuracy: 0.2837\n",
      "Epoch 22: categorical_accuracy did not improve from 0.28897\n",
      "178/178 [==============================] - 64s 359ms/step - loss: 1.3827 - categorical_accuracy: 0.2837 - val_loss: 1.3838 - val_categorical_accuracy: 0.2828 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3812 - categorical_accuracy: 0.2918\n",
      "Epoch 23: categorical_accuracy improved from 0.28897 to 0.29178, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 64s 358ms/step - loss: 1.3812 - categorical_accuracy: 0.2918 - val_loss: 1.3816 - val_categorical_accuracy: 0.3016 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3850 - categorical_accuracy: 0.2746\n",
      "Epoch 24: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 64s 359ms/step - loss: 1.3850 - categorical_accuracy: 0.2746 - val_loss: 1.3817 - val_categorical_accuracy: 0.3016 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3835 - categorical_accuracy: 0.2834\n",
      "Epoch 25: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 62s 349ms/step - loss: 1.3835 - categorical_accuracy: 0.2834 - val_loss: 1.3815 - val_categorical_accuracy: 0.3094 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3847 - categorical_accuracy: 0.2697\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 26: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 63s 351ms/step - loss: 1.3847 - categorical_accuracy: 0.2697 - val_loss: 1.3783 - val_categorical_accuracy: 0.3203 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3835 - categorical_accuracy: 0.2791\n",
      "Epoch 27: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 62s 347ms/step - loss: 1.3835 - categorical_accuracy: 0.2791 - val_loss: 1.3807 - val_categorical_accuracy: 0.3063 - lr: 2.0000e-04\n",
      "Epoch 28/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3839 - categorical_accuracy: 0.2753\n",
      "Epoch 28: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 59s 332ms/step - loss: 1.3839 - categorical_accuracy: 0.2753 - val_loss: 1.3783 - val_categorical_accuracy: 0.3219 - lr: 2.0000e-04\n",
      "Epoch 29/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3828 - categorical_accuracy: 0.2791\n",
      "Epoch 29: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 59s 330ms/step - loss: 1.3828 - categorical_accuracy: 0.2791 - val_loss: 1.3820 - val_categorical_accuracy: 0.3125 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3832 - categorical_accuracy: 0.2791\n",
      "Epoch 30: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 59s 332ms/step - loss: 1.3832 - categorical_accuracy: 0.2791 - val_loss: 1.3823 - val_categorical_accuracy: 0.2984 - lr: 2.0000e-04\n",
      "Epoch 31/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3827 - categorical_accuracy: 0.2781\n",
      "Epoch 31: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 59s 329ms/step - loss: 1.3827 - categorical_accuracy: 0.2781 - val_loss: 1.3846 - val_categorical_accuracy: 0.2828 - lr: 2.0000e-04\n",
      "Epoch 32/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3837 - categorical_accuracy: 0.2830\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 32: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 60s 335ms/step - loss: 1.3837 - categorical_accuracy: 0.2830 - val_loss: 1.3844 - val_categorical_accuracy: 0.2906 - lr: 2.0000e-04\n",
      "Epoch 33/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3846 - categorical_accuracy: 0.2774\n",
      "Epoch 33: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 60s 335ms/step - loss: 1.3846 - categorical_accuracy: 0.2774 - val_loss: 1.3869 - val_categorical_accuracy: 0.2641 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3850 - categorical_accuracy: 0.2662\n",
      "Epoch 34: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 59s 332ms/step - loss: 1.3850 - categorical_accuracy: 0.2662 - val_loss: 1.3809 - val_categorical_accuracy: 0.3141 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3835 - categorical_accuracy: 0.2781\n",
      "Epoch 35: categorical_accuracy did not improve from 0.29178\n",
      "178/178 [==============================] - 59s 330ms/step - loss: 1.3835 - categorical_accuracy: 0.2781 - val_loss: 1.3806 - val_categorical_accuracy: 0.3094 - lr: 4.0000e-05\n",
      "Epoch 35: early stopping\n"
     ]
    }
   ],
   "source": [
    "vgg16_conv = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg16_conv.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "vgg_feedforward = Flatten()(vgg16_conv.output)\n",
    "vgg_feedforward = Dense(64,activation = 'relu')(vgg_feedforward)\n",
    "vgg_feedforward = Dense(16,activation = 'relu')(vgg_feedforward)\n",
    "\n",
    "prediction = Dense(len(folders), activation='softmax')(vgg_feedforward)\n",
    "\n",
    "model_vgg16 = Model(inputs=vgg16_conv.input, outputs=prediction)\n",
    "\n",
    "model_vgg16.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model1_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model1_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "\n",
    "# Automatically saves the best weights of the model, based on best val_accuracy\n",
    "model1_mcp = ModelCheckpoint(filepath = r'temp\\model1_weights.h5', monitor = 'categorical_accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n",
    "vgg16_fit = model_vgg16.fit(\n",
    "  train,\n",
    "  validation_data=test,\n",
    "  epochs=100,\n",
    "  steps_per_epoch=5712//32,\n",
    "  validation_steps=1311//32,\n",
    "  callbacks=[model1_es, model1_rlr, model1_mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                1605696   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,321,492\n",
      "Trainable params: 8,686,228\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('models/vgg16_64_16_last_conv_train.h5') is False:\n",
    "    model_vgg16.save('models/vgg16_64_16_last_conv_train.h5')\n",
    "\n",
    "vgg16_64_16_last_conv_trained = load_model('models/vgg16_64_16_last_conv_train.h5')\n",
    "print(vgg16_64_16_last_conv_trained.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 - ResNet150 (No Convolution Trained) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234545216/234545216 [==============================] - 24s 0us/step\n",
      "Epoch 1/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 3.8381 - categorical_accuracy: 0.7900\n",
      "Epoch 1: categorical_accuracy improved from -inf to 0.79003, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 107s 532ms/step - loss: 3.8381 - categorical_accuracy: 0.7900 - val_loss: 4.1131 - val_categorical_accuracy: 0.8141 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 3.0886 - categorical_accuracy: 0.8652\n",
      "Epoch 2: categorical_accuracy improved from 0.79003 to 0.86517, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 69s 386ms/step - loss: 3.0886 - categorical_accuracy: 0.8652 - val_loss: 3.2448 - val_categorical_accuracy: 0.8703 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 2.7640 - categorical_accuracy: 0.8908\n",
      "Epoch 3: categorical_accuracy improved from 0.86517 to 0.89080, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 61s 341ms/step - loss: 2.7640 - categorical_accuracy: 0.8908 - val_loss: 2.5606 - val_categorical_accuracy: 0.9031 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.9824 - categorical_accuracy: 0.9182\n",
      "Epoch 4: categorical_accuracy improved from 0.89080 to 0.91819, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 59s 326ms/step - loss: 1.9824 - categorical_accuracy: 0.9182 - val_loss: 2.5364 - val_categorical_accuracy: 0.9031 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 2.2321 - categorical_accuracy: 0.9185\n",
      "Epoch 5: categorical_accuracy improved from 0.91819 to 0.91854, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 321ms/step - loss: 2.2321 - categorical_accuracy: 0.9185 - val_loss: 2.6831 - val_categorical_accuracy: 0.9156 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.9184 - categorical_accuracy: 0.9287\n",
      "Epoch 6: categorical_accuracy improved from 0.91854 to 0.92872, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 1.9184 - categorical_accuracy: 0.9287 - val_loss: 2.1032 - val_categorical_accuracy: 0.9156 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.7831 - categorical_accuracy: 0.9294\n",
      "Epoch 7: categorical_accuracy improved from 0.92872 to 0.92942, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 320ms/step - loss: 1.7831 - categorical_accuracy: 0.9294 - val_loss: 3.0945 - val_categorical_accuracy: 0.9062 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.5755 - categorical_accuracy: 0.9424\n",
      "Epoch 8: categorical_accuracy improved from 0.92942 to 0.94242, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 56s 315ms/step - loss: 1.5755 - categorical_accuracy: 0.9424 - val_loss: 1.6030 - val_categorical_accuracy: 0.9359 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3740 - categorical_accuracy: 0.9505\n",
      "Epoch 9: categorical_accuracy improved from 0.94242 to 0.95049, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 1.3740 - categorical_accuracy: 0.9505 - val_loss: 1.9588 - val_categorical_accuracy: 0.9344 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.6037 - categorical_accuracy: 0.9417\n",
      "Epoch 10: categorical_accuracy did not improve from 0.95049\n",
      "178/178 [==============================] - 52s 291ms/step - loss: 1.6037 - categorical_accuracy: 0.9417 - val_loss: 2.3160 - val_categorical_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.2297 - categorical_accuracy: 0.9565\n",
      "Epoch 11: categorical_accuracy improved from 0.95049 to 0.95646, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 318ms/step - loss: 1.2297 - categorical_accuracy: 0.9565 - val_loss: 2.5801 - val_categorical_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3642 - categorical_accuracy: 0.9582\n",
      "Epoch 12: categorical_accuracy improved from 0.95646 to 0.95822, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 319ms/step - loss: 1.3642 - categorical_accuracy: 0.9582 - val_loss: 2.3457 - val_categorical_accuracy: 0.9203 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.3377 - categorical_accuracy: 0.9508\n",
      "Epoch 13: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 52s 291ms/step - loss: 1.3377 - categorical_accuracy: 0.9508 - val_loss: 2.8326 - val_categorical_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 1.5956 - categorical_accuracy: 0.9526\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 14: categorical_accuracy did not improve from 0.95822\n",
      "178/178 [==============================] - 54s 301ms/step - loss: 1.5956 - categorical_accuracy: 0.9526 - val_loss: 3.5592 - val_categorical_accuracy: 0.9141 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.8763 - categorical_accuracy: 0.9726\n",
      "Epoch 15: categorical_accuracy improved from 0.95822 to 0.97261, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 320ms/step - loss: 0.8763 - categorical_accuracy: 0.9726 - val_loss: 1.1883 - val_categorical_accuracy: 0.9594 - lr: 2.0000e-04\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4261 - categorical_accuracy: 0.9810\n",
      "Epoch 16: categorical_accuracy improved from 0.97261 to 0.98104, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 57s 321ms/step - loss: 0.4261 - categorical_accuracy: 0.9810 - val_loss: 1.2461 - val_categorical_accuracy: 0.9547 - lr: 2.0000e-04\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.6029 - categorical_accuracy: 0.9782\n",
      "Epoch 17: categorical_accuracy did not improve from 0.98104\n",
      "178/178 [==============================] - 53s 294ms/step - loss: 0.6029 - categorical_accuracy: 0.9782 - val_loss: 0.5958 - val_categorical_accuracy: 0.9672 - lr: 2.0000e-04\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3923 - categorical_accuracy: 0.9796\n",
      "Epoch 18: categorical_accuracy did not improve from 0.98104\n",
      "178/178 [==============================] - 53s 295ms/step - loss: 0.3923 - categorical_accuracy: 0.9796 - val_loss: 1.0593 - val_categorical_accuracy: 0.9578 - lr: 2.0000e-04\n",
      "Epoch 19/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3100 - categorical_accuracy: 0.9828\n",
      "Epoch 19: categorical_accuracy improved from 0.98104 to 0.98279, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 326ms/step - loss: 0.3100 - categorical_accuracy: 0.9828 - val_loss: 1.1217 - val_categorical_accuracy: 0.9625 - lr: 2.0000e-04\n",
      "Epoch 20/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3785 - categorical_accuracy: 0.9824\n",
      "Epoch 20: categorical_accuracy did not improve from 0.98279\n",
      "178/178 [==============================] - 53s 295ms/step - loss: 0.3785 - categorical_accuracy: 0.9824 - val_loss: 1.3372 - val_categorical_accuracy: 0.9609 - lr: 2.0000e-04\n",
      "Epoch 21/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3281 - categorical_accuracy: 0.9814\n",
      "Epoch 21: categorical_accuracy did not improve from 0.98279\n",
      "178/178 [==============================] - 53s 297ms/step - loss: 0.3281 - categorical_accuracy: 0.9814 - val_loss: 0.8023 - val_categorical_accuracy: 0.9688 - lr: 2.0000e-04\n",
      "Epoch 22/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3610 - categorical_accuracy: 0.9860\n",
      "Epoch 22: categorical_accuracy improved from 0.98279 to 0.98596, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 325ms/step - loss: 0.3610 - categorical_accuracy: 0.9860 - val_loss: 0.9564 - val_categorical_accuracy: 0.9609 - lr: 2.0000e-04\n",
      "Epoch 23/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2801 - categorical_accuracy: 0.9853\n",
      "Epoch 23: categorical_accuracy did not improve from 0.98596\n",
      "178/178 [==============================] - 53s 296ms/step - loss: 0.2801 - categorical_accuracy: 0.9853 - val_loss: 0.5653 - val_categorical_accuracy: 0.9656 - lr: 2.0000e-04\n",
      "Epoch 24/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2507 - categorical_accuracy: 0.9874\n",
      "Epoch 24: categorical_accuracy improved from 0.98596 to 0.98736, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 323ms/step - loss: 0.2507 - categorical_accuracy: 0.9874 - val_loss: 1.2418 - val_categorical_accuracy: 0.9516 - lr: 2.0000e-04\n",
      "Epoch 25/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2140 - categorical_accuracy: 0.9863\n",
      "Epoch 25: categorical_accuracy did not improve from 0.98736\n",
      "178/178 [==============================] - 53s 297ms/step - loss: 0.2140 - categorical_accuracy: 0.9863 - val_loss: 1.0700 - val_categorical_accuracy: 0.9594 - lr: 2.0000e-04\n",
      "Epoch 26/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2682 - categorical_accuracy: 0.9870\n",
      "Epoch 26: categorical_accuracy did not improve from 0.98736\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.2682 - categorical_accuracy: 0.9870 - val_loss: 0.6802 - val_categorical_accuracy: 0.9703 - lr: 2.0000e-04\n",
      "Epoch 27/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4651 - categorical_accuracy: 0.9821\n",
      "Epoch 27: categorical_accuracy did not improve from 0.98736\n",
      "178/178 [==============================] - 53s 300ms/step - loss: 0.4651 - categorical_accuracy: 0.9821 - val_loss: 1.0255 - val_categorical_accuracy: 0.9688 - lr: 2.0000e-04\n",
      "Epoch 28/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.3278 - categorical_accuracy: 0.9821\n",
      "Epoch 28: categorical_accuracy did not improve from 0.98736\n",
      "178/178 [==============================] - 54s 300ms/step - loss: 0.3278 - categorical_accuracy: 0.9821 - val_loss: 0.6105 - val_categorical_accuracy: 0.9766 - lr: 2.0000e-04\n",
      "Epoch 29/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.2272 - categorical_accuracy: 0.9891\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 29: categorical_accuracy improved from 0.98736 to 0.98912, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 324ms/step - loss: 0.2272 - categorical_accuracy: 0.9891 - val_loss: 1.2003 - val_categorical_accuracy: 0.9594 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1896 - categorical_accuracy: 0.9877\n",
      "Epoch 30: categorical_accuracy did not improve from 0.98912\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1896 - categorical_accuracy: 0.9877 - val_loss: 1.0536 - val_categorical_accuracy: 0.9625 - lr: 4.0000e-05\n",
      "Epoch 31/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1498 - categorical_accuracy: 0.9916\n",
      "Epoch 31: categorical_accuracy improved from 0.98912 to 0.99157, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 63s 353ms/step - loss: 0.1498 - categorical_accuracy: 0.9916 - val_loss: 0.6922 - val_categorical_accuracy: 0.9703 - lr: 4.0000e-05\n",
      "Epoch 32/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1426 - categorical_accuracy: 0.9909\n",
      "Epoch 32: categorical_accuracy did not improve from 0.99157\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1426 - categorical_accuracy: 0.9909 - val_loss: 0.5339 - val_categorical_accuracy: 0.9750 - lr: 4.0000e-05\n",
      "Epoch 33/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1501 - categorical_accuracy: 0.9881\n",
      "Epoch 33: categorical_accuracy did not improve from 0.99157\n",
      "178/178 [==============================] - 53s 300ms/step - loss: 0.1501 - categorical_accuracy: 0.9881 - val_loss: 0.7968 - val_categorical_accuracy: 0.9719 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1456 - categorical_accuracy: 0.9937\n",
      "Epoch 34: categorical_accuracy improved from 0.99157 to 0.99368, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 326ms/step - loss: 0.1456 - categorical_accuracy: 0.9937 - val_loss: 1.0532 - val_categorical_accuracy: 0.9641 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1097 - categorical_accuracy: 0.9891\n",
      "Epoch 35: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1097 - categorical_accuracy: 0.9891 - val_loss: 0.6241 - val_categorical_accuracy: 0.9719 - lr: 4.0000e-05\n",
      "Epoch 36/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1214 - categorical_accuracy: 0.9902\n",
      "Epoch 36: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1214 - categorical_accuracy: 0.9902 - val_loss: 0.7752 - val_categorical_accuracy: 0.9688 - lr: 4.0000e-05\n",
      "Epoch 37/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0895 - categorical_accuracy: 0.9930\n",
      "Epoch 37: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 55s 310ms/step - loss: 0.0895 - categorical_accuracy: 0.9930 - val_loss: 0.8077 - val_categorical_accuracy: 0.9609 - lr: 4.0000e-05\n",
      "Epoch 38/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1845 - categorical_accuracy: 0.9916\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 38: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1845 - categorical_accuracy: 0.9916 - val_loss: 0.6946 - val_categorical_accuracy: 0.9703 - lr: 4.0000e-05\n",
      "Epoch 39/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1511 - categorical_accuracy: 0.9923\n",
      "Epoch 39: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1511 - categorical_accuracy: 0.9923 - val_loss: 0.8041 - val_categorical_accuracy: 0.9688 - lr: 8.0000e-06\n",
      "Epoch 40/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1825 - categorical_accuracy: 0.9884\n",
      "Epoch 40: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1825 - categorical_accuracy: 0.9884 - val_loss: 0.6474 - val_categorical_accuracy: 0.9719 - lr: 8.0000e-06\n",
      "Epoch 41/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1662 - categorical_accuracy: 0.9877\n",
      "Epoch 41: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1662 - categorical_accuracy: 0.9877 - val_loss: 0.8556 - val_categorical_accuracy: 0.9703 - lr: 8.0000e-06\n",
      "Epoch 42/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0934 - categorical_accuracy: 0.9937\n",
      "Epoch 42: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.0934 - categorical_accuracy: 0.9937 - val_loss: 1.0211 - val_categorical_accuracy: 0.9703 - lr: 8.0000e-06\n",
      "Epoch 43/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1363 - categorical_accuracy: 0.9916\n",
      "Epoch 43: categorical_accuracy did not improve from 0.99368\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1363 - categorical_accuracy: 0.9916 - val_loss: 1.3061 - val_categorical_accuracy: 0.9641 - lr: 8.0000e-06\n",
      "Epoch 44/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0637 - categorical_accuracy: 0.9947\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 44: categorical_accuracy improved from 0.99368 to 0.99473, saving model to temp\\model1_weights.h5\n",
      "178/178 [==============================] - 58s 325ms/step - loss: 0.0637 - categorical_accuracy: 0.9947 - val_loss: 0.8738 - val_categorical_accuracy: 0.9719 - lr: 8.0000e-06\n",
      "Epoch 45/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1414 - categorical_accuracy: 0.9923\n",
      "Epoch 45: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 296ms/step - loss: 0.1414 - categorical_accuracy: 0.9923 - val_loss: 0.5309 - val_categorical_accuracy: 0.9719 - lr: 1.6000e-06\n",
      "Epoch 46/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1623 - categorical_accuracy: 0.9909\n",
      "Epoch 46: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1623 - categorical_accuracy: 0.9909 - val_loss: 0.9188 - val_categorical_accuracy: 0.9641 - lr: 1.6000e-06\n",
      "Epoch 47/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0800 - categorical_accuracy: 0.9947\n",
      "Epoch 47: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 54s 304ms/step - loss: 0.0800 - categorical_accuracy: 0.9947 - val_loss: 1.0642 - val_categorical_accuracy: 0.9641 - lr: 1.6000e-06\n",
      "Epoch 48/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0798 - categorical_accuracy: 0.9930\n",
      "Epoch 48: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 297ms/step - loss: 0.0798 - categorical_accuracy: 0.9930 - val_loss: 0.3697 - val_categorical_accuracy: 0.9828 - lr: 1.6000e-06\n",
      "Epoch 49/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1160 - categorical_accuracy: 0.9926\n",
      "Epoch 49: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1160 - categorical_accuracy: 0.9926 - val_loss: 0.8846 - val_categorical_accuracy: 0.9719 - lr: 1.6000e-06\n",
      "Epoch 50/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1704 - categorical_accuracy: 0.9905\n",
      "Epoch 50: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1704 - categorical_accuracy: 0.9905 - val_loss: 0.6654 - val_categorical_accuracy: 0.9766 - lr: 1.6000e-06\n",
      "Epoch 51/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0842 - categorical_accuracy: 0.9926\n",
      "Epoch 51: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 297ms/step - loss: 0.0842 - categorical_accuracy: 0.9926 - val_loss: 0.7456 - val_categorical_accuracy: 0.9734 - lr: 1.6000e-06\n",
      "Epoch 52/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1415 - categorical_accuracy: 0.9902\n",
      "Epoch 52: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 54s 303ms/step - loss: 0.1415 - categorical_accuracy: 0.9902 - val_loss: 0.5013 - val_categorical_accuracy: 0.9734 - lr: 1.6000e-06\n",
      "Epoch 53/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1166 - categorical_accuracy: 0.9916\n",
      "Epoch 53: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.1166 - categorical_accuracy: 0.9916 - val_loss: 0.6591 - val_categorical_accuracy: 0.9781 - lr: 1.6000e-06\n",
      "Epoch 54/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0938 - categorical_accuracy: 0.9937\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 54: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 53s 299ms/step - loss: 0.0938 - categorical_accuracy: 0.9937 - val_loss: 0.9038 - val_categorical_accuracy: 0.9688 - lr: 1.6000e-06\n",
      "Epoch 55/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1513 - categorical_accuracy: 0.9926\n",
      "Epoch 55: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 54s 301ms/step - loss: 0.1513 - categorical_accuracy: 0.9926 - val_loss: 0.6386 - val_categorical_accuracy: 0.9781 - lr: 3.2000e-07\n",
      "Epoch 56/100\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.1064 - categorical_accuracy: 0.9937\n",
      "Epoch 56: categorical_accuracy did not improve from 0.99473\n",
      "178/178 [==============================] - 52s 292ms/step - loss: 0.1064 - categorical_accuracy: 0.9937 - val_loss: 0.4267 - val_categorical_accuracy: 0.9719 - lr: 3.2000e-07\n",
      "Epoch 56: early stopping\n"
     ]
    }
   ],
   "source": [
    "ResNet_conv = ResNet152V2(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in ResNet_conv.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "resnet_feedforword = Flatten()(ResNet_conv.output)\n",
    "\n",
    "prediction = Dense(len(folders), activation='softmax')(resnet_feedforword)\n",
    "\n",
    "model_ResNet = Model(inputs= ResNet_conv.input, outputs=prediction)\n",
    "\n",
    "model_ResNet.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "model1_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model1_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "model1_mcp = ModelCheckpoint(filepath = r'temp\\model1_weights.h5', monitor = 'categorical_accuracy',\n",
    "                             save_best_only = True, verbose = 1)\n",
    "\n",
    "model_ResNet_fit = model_ResNet.fit(\n",
    "  train,\n",
    "  validation_data=test,\n",
    "  epochs=100,\n",
    "  steps_per_epoch=5712//32,\n",
    "  validation_steps=1311//32,\n",
    "  callbacks=[model1_es, model1_rlr, model1_mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('tf2.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "927d683070d8f87e257ecab0c999e91a9159e1dddb39dd14b355c9356536362e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
